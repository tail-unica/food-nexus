{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save rows from HUMMUS and open food facts  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from file_creation import extract_rows\n",
    "\n",
    "rows = 3\n",
    "\n",
    "input_file = \"../csv_file/pp_recipes.csv\"\n",
    "output_file = \"../csv_file/pp_recipes_rows.csv\"\n",
    "extract_rows(input_file, output_file, rows=rows)\n",
    "\n",
    "input_file = \"../csv_file/pp_members.csv\"\n",
    "output_file = \"../csv_file/pp_members_rows.csv\"\n",
    "extract_rows(input_file, output_file, rows=rows)\n",
    "\n",
    "input_file = \"../csv_file/pp_reviews.csv\"\n",
    "output_file = \"../csv_file/pp_reviews_rows.csv\"\n",
    "extract_rows(input_file, output_file, rows=rows)\n",
    "\n",
    "input_file = \"../csv_file/off.csv\"\n",
    "output_file = \"../csv_file/off_rows.csv\"\n",
    "extract_rows(input_file, output_file, rows=rows, delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save casual row from off to create a test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from file_creation import extract_rows_random\n",
    "\n",
    "rows = 200\n",
    "input_file = \"../csv_file/off.csv\"\n",
    "output_file = \"../csv_file/off_rows_casual.csv\"\n",
    "extract_rows_random(input_file, output_file, rows=rows, delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save recipe name from hummus and open food facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from file_creation import extract_recipes\n",
    "\n",
    "rows = 3\n",
    "\n",
    "input_file = \"../csv_file/pp_recipes.csv\"\n",
    "output_file = \"../csv_file/hummus_recipes.csv\"\n",
    "extract_recipes(input_file, output_file, column_name=\"title\", rows=rows)\n",
    "\n",
    "input_file = \"../csv_file/off.csv\"\n",
    "output_file = \"../csv_file/off_recipes.csv\"\n",
    "extract_recipes(\n",
    "    input_file,\n",
    "    output_file,\n",
    "    column_name=\"product_name\",\n",
    "    rows=rows,\n",
    "    delimiter1=\"\\t\",\n",
    "    delimiter2=\" \",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save ingredients name from foodKg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from file_creation import extract_ingredients_foodkg\n",
    "\n",
    "input_file = \"../csv_file/pp_recipes.csv\"\n",
    "output_file = \"../csv_file/ingredients_food_kg.csv\"\n",
    "extract_ingredients_foodkg(\n",
    "    input_file=input_file, output_file=output_file, min_occurrences=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save all adjectives from FoodKG food"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from file_creation import extract_adjectives_foodkg\n",
    "\n",
    "input_file = \"../csv_file/ingredients_food_kg.csv\"\n",
    "output_file = \"../csv_file/aggettivi_FoodKg.csv\"\n",
    "extract_adjectives_foodkg(\n",
    "    input_file=input_file, output_file=output_file, text_column=\"ingredient\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save all tags from HUMMUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from file_creation import extract_tags_unique\n",
    "\n",
    "extract_tags_unique(\n",
    "    \"../csv_file/pp_recipes.csv\", \"../csv_file/tag_hummus_frequency.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save brand that appear more than n times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from file_creation import extract_clean_brands\n",
    "\n",
    "input_file = \"../csv_file/off.csv\"\n",
    "output_file = \"../csv_file/brands.csv\"\n",
    "extract_clean_brands(input_file=input_file, output_file=output_file, n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brand filtering with the food expert model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clean the brand file from food names and save it as a new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from file_creation import brand_filtering\n",
    "\n",
    "file = \"../csv_file/brands.csv\"\n",
    "output_file = \"../csv_file/brands_filtered.csv\"\n",
    "brand_filtering(file, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a file with some member description for test the attribute extractor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from file_creation import extract_description\n",
    "\n",
    "rows = 20\n",
    "input_file = \"../csv_file/pp_members.csv\"\n",
    "output_file = \"../csv_file/user_description.csv\"\n",
    "extract_description(input_file, output_file, column_name=\"member_description\", rows=rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add the group tag to the recipes file\n",
    "\n",
    "(In future work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from file_creation import transform_groups_in_tags\n",
    "#\n",
    "#transform_groups_in_tags(\n",
    "#    \"../csv_file/recipes_pp_binned.csv\",\n",
    "#    \"../csv_file/pp_recipes_groups.csv\",\n",
    "#    [\"protein_group\",\"calories_group\",\"calories_from_fat_group\",\"total_fat_group\",\"saturated_fat_group\",\"cholesterol_group\",\"sodium_group\",\"carbohydrate_group\",\"dietary_fiber_group\",\"sugars_group\",\"duration_group\"],\n",
    "#    delimiter1=\",\",\n",
    "#    delimiter2=\";\"\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save all the member description with their associated member id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from file_creation import save_some_column\n",
    "\n",
    "input_csv = \"../csv_file/pp_members.csv\"\n",
    "output_csv = \"../csv_file/member_description_list.csv\"\n",
    "column1 = \"member_id\"\n",
    "column2 = \"member_description\"\n",
    "\n",
    "save_some_column(input_csv, output_csv, column1, column2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from file_creation import save_some_column\n",
    "\n",
    "input_csv = \"../csv_file/pp_reviews.csv\"\n",
    "output_csv = \"../csv_file/member_review_list.csv\"\n",
    "column1 = \"member_id\"\n",
    "column2 = \"text\"\n",
    "\n",
    "save_some_column(input_csv, output_csv, column1, column2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file1 = \"../csv_file/member_description_list.csv\"\n",
    "file2 = \"../csv_file/member_review_list.csv\"\n",
    "output_csv = \"../csv_file/member_complete_info_list.csv\"\n",
    "\n",
    "df1 = pd.read_csv(file1)\n",
    "df2 = pd.read_csv(file2)\n",
    "\n",
    "merged_df = df1.merge(df2, on=\"member_id\", how=\"left\")\n",
    "\n",
    "def build_information(row):\n",
    "    info = [f\"member description: {row['member_description']}\"]\n",
    "    reviews = row['text'].dropna().tolist() if isinstance(row['text'], pd.Series) else [row['text']]\n",
    "    for i, review in enumerate(reviews, start=1):\n",
    "        info.append(f\"review number {i}: {review}\")\n",
    "    return \"; \".join(info)\n",
    "\n",
    "merged_df[\"information\"] = merged_df.apply(build_information, axis=1)\n",
    "\n",
    "final_df = merged_df[[\"member_id\", \"information\"]]\n",
    "\n",
    "final_df.to_csv(output_csv, index=False)\n",
    "print(f\"File saved: {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script is used to handle a problem encountered in the encoding process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "\n",
    "def change_csv_delimiter(file_path, current_delimiter_char, new_delimiter_char, max_rows_to_read=None):\n",
    "    df = pd.read_csv(\n",
    "        file_path,\n",
    "        sep=current_delimiter_char,\n",
    "        nrows=max_rows_to_read,\n",
    "        engine='python',\n",
    "        quotechar='\"',\n",
    "        quoting=csv.QUOTE_MINIMAL,\n",
    "        doublequote=True,\n",
    "        on_bad_lines='skip',\n",
    "        dtype=str\n",
    "    )\n",
    "\n",
    "    df.replace(r'^\\s*$', pd.NA, regex=True, inplace=True)\n",
    "    df.dropna(how='all', inplace=True)\n",
    "\n",
    "    dir_name = os.path.dirname(file_path)\n",
    "    base_name = os.path.basename(file_path)\n",
    "    temp_base_name = \".temp_conversion_\" + base_name\n",
    "    temp_output_file_path = os.path.join(dir_name, temp_base_name)\n",
    "    \n",
    "    df.to_csv(temp_output_file_path, sep=new_delimiter_char, index=False, quoting=csv.QUOTE_MINIMAL)\n",
    "    \n",
    "    os.remove(file_path)\n",
    "    os.rename(temp_output_file_path, file_path)\n",
    "\n",
    "path_to_csv_file_for_modification = \"../csv_file/pp_recipes.csv\"\n",
    "original_file_delimiter_char = \",\"\n",
    "target_file_delimiter_char = \";\"\n",
    "row_processing_read_limit = None\n",
    "\n",
    "change_csv_delimiter(\n",
    "    file_path=path_to_csv_file_for_modification,\n",
    "    current_delimiter_char=original_file_delimiter_char,\n",
    "    new_delimiter_char=target_file_delimiter_char,\n",
    "    max_rows_to_read=row_processing_read_limit\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ambientez",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
