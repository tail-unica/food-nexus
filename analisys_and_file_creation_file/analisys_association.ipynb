{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b531aba7",
   "metadata": {},
   "source": [
    "# Hummus-OFF Attribute Coverage Analysis Script\n",
    "\n",
    "This Python script analyzes the \"coverage\" of product attributes from an Open Food Facts (OFF) dataset within a collection of recipes. The primary goal is to determine, for each product attribute, how many unique recipes are associated with products that possess that attribute with a valid, non-generic value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd78369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hummus caricato: 507335 righe\n",
      "Mapping caricato: 37796563 righe\n",
      "Hummus filtrato su ricette con mapping (rilevanti per il numeratore): 493749 righe\n",
      "Trovati 208 attributi da controllare in off_df\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing OFF chunks: 9chunk [15:44, 104.96s/chunk]\n",
      "Calculating percentages: 100%|██████████| 208/208 [07:53<00:00,  2.28s/attribute]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "import gc\n",
    "\n",
    "hummus_df = pd.read_csv(\"../csv_file/pp_recipes_normalized_by_pipeline.csv\", sep=\";\", low_memory=False, on_bad_lines=\"skip\")\n",
    "\n",
    "original_total_unique_recipes  = len(hummus_df)\n",
    "print(f\"Hummus loaded: {original_total_unique_recipes} rows\")\n",
    "\n",
    "mapping_df = pd.read_csv(\"../csv_file/file_off_hummus.csv\", sep=\",\", low_memory=False, on_bad_lines=\"skip\")\n",
    "print(f\"Mapping loaded: {len(mapping_df)} righe\")\n",
    "\n",
    "valid_titles_in_mapping = set(mapping_df['title_normalized'].unique())\n",
    "hummus_df_relevant = hummus_df[hummus_df['title_normalized'].isin(valid_titles_in_mapping)].copy()\n",
    "print(f\"Hummus filtered on recipes with mapping (relevant for the numerator): {len(hummus_df_relevant)} righe\")\n",
    "\n",
    "needed_off_products = set(mapping_df['product_name_normalized'].unique())\n",
    "off_file_path = \"../csv_file/off_normalized_final.csv\"\n",
    "\n",
    "off_cols_df = pd.read_csv(off_file_path, sep=\"\\t\", nrows=0)\n",
    "off_cols = off_cols_df.columns.tolist()\n",
    "off_attributes = [col for col in off_cols]\n",
    "print(f\"Founded {len(off_attributes)} attributes to check in off_df\")\n",
    "\n",
    "valid_products_per_attribute = {attr: set() for attr in off_attributes}\n",
    "\n",
    "off_reader = pd.read_csv(\n",
    "    off_file_path,\n",
    "    sep=\"\\t\",\n",
    "    low_memory=False,\n",
    "    on_bad_lines=\"skip\",\n",
    "    chunksize=300000,\n",
    "    iterator=True,\n",
    "    usecols=off_attributes\n",
    ")\n",
    "\n",
    "processed_chunks = 0\n",
    "for chunk in tqdm(off_reader, desc=\"Processing OFF chunks\", unit=\"chunk\"):\n",
    "    processed_chunks += 1\n",
    "\n",
    "    chunk.dropna(subset=['product_name_normalized'], inplace=True)\n",
    "    chunk = chunk[chunk['product_name_normalized'].isin(needed_off_products)]\n",
    "    if chunk.empty:\n",
    "        del chunk\n",
    "        gc.collect()\n",
    "        continue\n",
    "\n",
    "    for attribute in off_attributes:\n",
    "        if attribute in chunk.columns:\n",
    "            mask = chunk[attribute].notna() & (chunk[attribute].astype(str).str.strip() != '') & (chunk[attribute].astype(str).str.strip() != 'unknown') & (chunk[attribute].astype(str).str.strip() != 'none')\n",
    "            valid_products_in_chunk = chunk.loc[mask, 'product_name_normalized']\n",
    "            valid_products_per_attribute[attribute].update(valid_products_in_chunk)\n",
    "\n",
    "attribute_counts = {}\n",
    "attribute_percentages = {}\n",
    "\n",
    "\n",
    "if len(hummus_df_relevant) > 0:\n",
    "    title_to_recipe_ids = hummus_df_relevant.groupby('title_normalized')['recipe_id'].apply(set).to_dict()\n",
    "else:\n",
    "    title_to_recipe_ids = {} \n",
    "\n",
    "for attr in tqdm(off_attributes, desc=\"Calculating percentages\", unit=\"attribute\"):\n",
    "    valid_products_for_this_attr = valid_products_per_attribute.get(attr, set())\n",
    "    count = 0 \n",
    "\n",
    "    if valid_products_for_this_attr and title_to_recipe_ids:\n",
    "        relevant_mappings = mapping_df[mapping_df['product_name_normalized'].isin(valid_products_for_this_attr)]\n",
    "        relevant_titles = set(relevant_mappings['title_normalized'].unique())\n",
    "        recipe_ids_with_valid_attr = set()\n",
    "        for title in relevant_titles:\n",
    "            ids_for_title = title_to_recipe_ids.get(title) \n",
    "            if ids_for_title:\n",
    "                recipe_ids_with_valid_attr.update(ids_for_title)\n",
    "\n",
    "        count = len(recipe_ids_with_valid_attr)\n",
    "\n",
    "    attribute_counts[attr] = count\n",
    "    percentage = (count / original_total_unique_recipes) * 100 if original_total_unique_recipes > 0 else 0\n",
    "    attribute_percentages[attr] = percentage\n",
    "\n",
    "\n",
    "result_df = pd.DataFrame({\n",
    "    'count': pd.Series(attribute_counts),\n",
    "    'percentage': pd.Series(attribute_percentages)\n",
    "})\n",
    "result_df = result_df.sort_values('percentage', ascending=False)\n",
    "result_df['percentage_str'] = result_df['percentage'].apply(lambda x: f\"{x:.2f}%\")\n",
    "result_df.index.name = 'attribute'\n",
    "\n",
    "output_path = \"../csv_file/hummus_off_attribute_coverage_85.csv\"\n",
    "result_df.to_csv(output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ambientez",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
