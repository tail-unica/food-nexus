{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIMILARITY WITH A CLASSIC BERT (Naive approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from entity_linking import find_most_similar_pairs, read_specified_columns\n",
    "\n",
    "file1_path = \"../csv_file/entity_linking_test.csv\"\n",
    "\n",
    "lists = read_specified_columns(file_path=file1_path, elenco_colonne=[\"off\", \"foodkg\"], delimiter=\",\")\n",
    "\n",
    "list1 = [item[0] for item in lists]\n",
    "list2 = [item[1] for item in lists]\n",
    "\n",
    "most_similar_pairs = find_most_similar_pairs(list1, list2)\n",
    "\n",
    "print(\"Most similar couples:\\n\")\n",
    "for item1, item2, score in most_similar_pairs:\n",
    "    print(f\"({item1}) --- ({item2}) --- Similarity: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNIVERSITY OF BARI METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from entity_linking import (\n",
    "    RecipeTransformer,\n",
    "    compute_embeddings,\n",
    "    find_similar_by_title,\n",
    "    read_specified_columns,\n",
    ")\n",
    "\n",
    "file1_path = \"../csv_file/entity_linking_test.csv\"\n",
    "\n",
    "lists = read_specified_columns(file_path=file1_path, elenco_colonne=[\"off\", \"foodkg\"], delimiter=\",\")\n",
    "\n",
    "list1 = [item[0] for item in lists]\n",
    "list2 = [item[1] for item in lists]\n",
    "\n",
    "\n",
    "# Initialize the transformer\n",
    "transformer_name = \"davanstrien/autotrain-recipes-2451975973\"\n",
    "transformer = RecipeTransformer(transformer_name)\n",
    "\n",
    "# Compute embeddings for all recipes in list2\n",
    "print(\"Calculating embeddings for list2...\")\n",
    "embeddings2 = compute_embeddings(list2, transformer)\n",
    "\n",
    "# Create a list of tuples (index, title) for list2\n",
    "entities_list2 = list(enumerate(iterable=list2))\n",
    "\n",
    "# Find the most similar recipe for each item in list1\n",
    "most_similar_pairs = []\n",
    "print(\"Searching for the most similar recipes...\")\n",
    "for recipe_title in tqdm(list1, desc=\"Similarity search\"):\n",
    "    similar_recipe, similarity_score = find_similar_by_title(\n",
    "        recipe_title, entities_list2, embeddings2, transformer\n",
    "    )\n",
    "    most_similar_pairs.append((recipe_title, similar_recipe[1], similarity_score))\n",
    "\n",
    "# Output the results\n",
    "print(\"Most similar recipe pairs found:\\n\")\n",
    "for item1, item2, score in most_similar_pairs:\n",
    "    print(f\"({item1}) --------- ({item2}) --------- Similarity: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IBRID METHOD WITH INDICATOR TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from entity_linking import find_k_most_similar_pairs_with_indicators\n",
    "\n",
    "list1 = [(\"Pasta\", 30, 5, 10, \"Pasta\"), (\"Pane\", 50, 1, 10, \"Pane\")]\n",
    "list2 = [(\"Riso\", 40, 2, 8, \"Riso\"), (\"Pizza\", 20, 10, 12, \"Pizza\")]\n",
    "result = find_k_most_similar_pairs_with_indicators(list1, list2, use_indicator=True)\n",
    "print(\"actual contribution\", result)\n",
    "\n",
    "list1 = [(\"Pasta\", 100, 0, 0, \"Pasta\"), (\"Pane\", 0, 0, 0, \"Pane\")]\n",
    "list2 = [(\"Riso\", 0, 2, 8, \"Riso\"), (\"Pizza\", 0, 50, 50, \"Pizza\")]\n",
    "result = find_k_most_similar_pairs_with_indicators(list1, list2, use_indicator=True)\n",
    "print(\"negative contribution\", result)\n",
    "\n",
    "list1 = [(\"Pasta\", 33, 33, 33, \"Pasta\"), (\"Pane\", 0, 0, 0, \"Pane\")]\n",
    "list2 = [(\"Riso\", 0, 2, 8, \"Riso\"), (\"Pizza\", 33, 33, 33 , \"Pizza\")]\n",
    "result = find_k_most_similar_pairs_with_indicators(list1, list2, use_indicator=True)\n",
    "print(\"positive contribution\", result)\n",
    "\n",
    "list1 = [(\"pasta\", \"pasta\"), (\"pane\", \"pane\")]\n",
    "list2 = [(\"riso\", \"riso\"), (\"pizza\", \"pizza\")]\n",
    "result = find_k_most_similar_pairs_with_indicators(list1, list2)\n",
    "print(\"no contribution\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST OF VARIOUS BERT MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "search of the best threshold value for the bert on a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75182a99783f40a69c3c261dadcedeba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 224.00 MiB. GPU 0 has a total capacity of 44.55 GiB of which 150.44 MiB is free. Process 3220499 has 23.22 GiB memory in use. Including non-PyTorch memory, this process has 21.17 GiB memory in use. Of the allocated memory 20.90 GiB is allocated by PyTorch, and 17.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 52\u001b[0m\n\u001b[1;32m     49\u001b[0m writer\u001b[38;5;241m.\u001b[39mwriterow(column_names)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m list_of_models:\n\u001b[0;32m---> 52\u001b[0m     model_name, vocab_size, number_of_parameters, accuracy, accuracy_considered, number_of_TP_and_TN, threshold \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_entity_linking_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreshold\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m modelz, vocab_sizez, number_of_parametersz, accuracyz, accuracy_consideredz, number_of_TP_and_TNz, thresholdz,  \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(model_name, vocab_size, number_of_parameters, accuracy, accuracy_considered, number_of_TP_and_TN, threshold):\n\u001b[1;32m     56\u001b[0m         writer\u001b[38;5;241m.\u001b[39mwriterow([model, vocab_sizez, number_of_parametersz, \u001b[38;5;28mround\u001b[39m(accuracyz, \u001b[38;5;241m2\u001b[39m), \u001b[38;5;28mround\u001b[39m(accuracy_consideredz) , number_of_TP_and_TNz, thresholdz])\n",
      "File \u001b[0;32m~/kgeats/entity_linking_file/entity_linking.py:366\u001b[0m, in \u001b[0;36mevaluate_entity_linking_method\u001b[0;34m(data, model, show_progress, threshold_list)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;66;03m# Apply the method\u001b[39;00m\n\u001b[1;32m    365\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# Number of results to consider\u001b[39;00m\n\u001b[0;32m--> 366\u001b[0m linked_entities \u001b[38;5;241m=\u001b[39m \u001b[43mfind_k_most_similar_pairs_with_indicators\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlist1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlist2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;66;03m# Evaluate results\u001b[39;00m\n\u001b[1;32m    371\u001b[0m accuracy_list \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/kgeats/entity_linking_file/entity_linking.py:280\u001b[0m, in \u001b[0;36mfind_k_most_similar_pairs_with_indicators\u001b[0;34m(list1, list2, k, model, use_indicator, batch_size)\u001b[0m\n\u001b[1;32m    277\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m# \"cuda\" if torch.cuda.is_available() else \"cpu\"\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;66;03m# Load the model\u001b[39;00m\n\u001b[0;32m--> 280\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSentenceTransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_indicator:\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;66;03m# Ensure each element in list1 and list2 has 4 elements by appending (0, 0, 0)\u001b[39;00m\n\u001b[1;32m    284\u001b[0m     list1 \u001b[38;5;241m=\u001b[39m [(item[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, item[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m list1]\n",
      "File \u001b[0;32m~/miniconda3/envs/ambientez/lib/python3.13/site-packages/sentence_transformers/SentenceTransformer.py:347\u001b[0m, in \u001b[0;36mSentenceTransformer.__init__\u001b[0;34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, similarity_fn_name, cache_folder, trust_remote_code, revision, local_files_only, token, use_auth_token, truncate_dim, model_kwargs, tokenizer_kwargs, config_kwargs, model_card_data, backend)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_hpu_graph_enabled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_prompt_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_prompt_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompts:\n",
      "File \u001b[0;32m~/miniconda3/envs/ambientez/lib/python3.13/site-packages/torch/nn/modules/module.py:1340\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1337\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1338\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ambientez/lib/python3.13/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ambientez/lib/python3.13/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 900 (4 times)]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/ambientez/lib/python3.13/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ambientez/lib/python3.13/site-packages/torch/nn/modules/module.py:927\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 927\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    930\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ambientez/lib/python3.13/site-packages/torch/nn/modules/module.py:1326\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1320\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1321\u001b[0m             device,\n\u001b[1;32m   1322\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1323\u001b[0m             non_blocking,\n\u001b[1;32m   1324\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1325\u001b[0m         )\n\u001b[0;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 224.00 MiB. GPU 0 has a total capacity of 44.55 GiB of which 150.44 MiB is free. Process 3220499 has 23.22 GiB memory in use. Including non-PyTorch memory, this process has 21.17 GiB memory in use. Of the allocated memory 20.90 GiB is allocated by PyTorch, and 17.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "from entity_linking import read_specified_columns, evaluate_entity_linking_method\n",
    "import csv\n",
    "\n",
    "file_path = \"../csv_file/entity_linking_test_normalized_validation.csv\"\n",
    "column_list = [\"off_normalized\", \"foodkg_normalized\"]\n",
    "data = read_specified_columns(file_path, elenco_colonne=column_list, delimiter=\",\")\n",
    "\n",
    "#https://huggingface.co/spaces/mteb/leaderboard 09/12/2024\n",
    "list_of_models = [\n",
    "    \n",
    "    #top 5 in pair classification (around 10000000 parameter)\n",
    "    #voyage is not free\n",
    "    #\"meta-llama/Meta-Llama-3-8B-Instruct\", # have problem with the token's padding\n",
    "    \"nvidia/NV-Embed-v2\",\n",
    "    \"Salesforce/SFR-Embedding-Mistral\",\n",
    "    \"compressa-ai/Compressa-Embeddings\",\n",
    "\n",
    "    # top 3 under 1000000 parameters\n",
    "    \"dunzhang/stella_en_400M_v5\",\n",
    "    \"llmrails/ember-v1\",\n",
    "    \"WhereIsAI/UAE-Large-V1\",\n",
    "\n",
    "    # top 3 under 100000 parameters\n",
    "    \"infgrad/stella-base-en-v2\",\n",
    "    \"intfloat/e5-small\",\n",
    "    \"BAAI/bge-small-en-v1.5\", \n",
    "\n",
    "    #top 5 overall\n",
    "    #nvidia/NV-Embed-v2 alredy tested\n",
    "    \"dunzhang/stella_en_1.5B_v5\",\n",
    "    \"BAAI/bge-en-icl\",\n",
    "    \"blevlabs/stella_en_v5\",\n",
    "    \"Salesforce/SFR-Embedding-2_R\",\n",
    "\n",
    "    # top 3 in sts\n",
    "    \"Lajavaness/bilingual-embedding-large\",\n",
    "    \"ilhamdprastyo/jina-embeddings-v3-tei\",\n",
    "    \"jinaai/jina-embeddings-v3\"\n",
    "    ]\n",
    "\n",
    "\n",
    "column_names = [\"model_name\", \"vocab_size\", \"number_of_parameters\", \"accuracy\", \"accuracy_on_considered\", \"number_of_TP_and_TN\", \"threshold\", ]\n",
    "threshold = [(i/100) for i in  range(80, 100, 1)]\n",
    "\n",
    "output_file = \"../csv_file/bert_comparison_validation.csv\"\n",
    "\n",
    "with open(output_file, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(column_names)\n",
    "    \n",
    "    for model in list_of_models:\n",
    "        model_name, vocab_size, number_of_parameters, accuracy, accuracy_considered, number_of_TP_and_TN, threshold = evaluate_entity_linking_method(\n",
    "            data, show_progress=False, model=model, threshold_list=threshold\n",
    "        )\n",
    "        for modelz, vocab_sizez, number_of_parametersz, accuracyz, accuracy_consideredz, number_of_TP_and_TNz, thresholdz,  in zip(model_name, vocab_size, number_of_parameters, accuracy, accuracy_considered, number_of_TP_and_TN, threshold):\n",
    "            writer.writerow([model, vocab_sizez, number_of_parametersz, round(accuracyz, 2), round(accuracy_consideredz) , number_of_TP_and_TNz, thresholdz])\n",
    "\n",
    "print(f\"file created {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "determine the best bert on a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Salesforce/SFR-Embedding-Mistral', 'Salesforce/SFR-Embedding-Mistral', 'Salesforce/SFR-Embedding-Mistral', 'Salesforce/SFR-Embedding-Mistral', 'Salesforce/SFR-Embedding-Mistral', 'Salesforce/SFR-Embedding-Mistral', 'Salesforce/SFR-Embedding-Mistral', 'Salesforce/SFR-Embedding-Mistral', 'Salesforce/SFR-Embedding-Mistral', 'Salesforce/SFR-Embedding-Mistral', 'Salesforce/SFR-Embedding-Mistral', 'Salesforce/SFR-Embedding-Mistral', 'Salesforce/SFR-Embedding-Mistral', 'Salesforce/SFR-Embedding-Mistral', 'Salesforce/SFR-Embedding-Mistral', 'Salesforce/SFR-Embedding-Mistral', 'Salesforce/SFR-Embedding-Mistral', 'Salesforce/SFR-Embedding-Mistral', 'Salesforce/SFR-Embedding-Mistral', 'Salesforce/SFR-Embedding-Mistral', 'compressa-ai/Compressa-Embeddings', 'compressa-ai/Compressa-Embeddings', 'compressa-ai/Compressa-Embeddings', 'compressa-ai/Compressa-Embeddings', 'compressa-ai/Compressa-Embeddings', 'compressa-ai/Compressa-Embeddings', 'compressa-ai/Compressa-Embeddings', 'compressa-ai/Compressa-Embeddings', 'compressa-ai/Compressa-Embeddings', 'compressa-ai/Compressa-Embeddings', 'compressa-ai/Compressa-Embeddings', 'compressa-ai/Compressa-Embeddings', 'compressa-ai/Compressa-Embeddings', 'compressa-ai/Compressa-Embeddings', 'compressa-ai/Compressa-Embeddings', 'compressa-ai/Compressa-Embeddings', 'compressa-ai/Compressa-Embeddings', 'compressa-ai/Compressa-Embeddings', 'compressa-ai/Compressa-Embeddings', 'compressa-ai/Compressa-Embeddings', 'dunzhang/stella_en_400M_v5', 'dunzhang/stella_en_400M_v5', 'dunzhang/stella_en_400M_v5', 'dunzhang/stella_en_400M_v5', 'dunzhang/stella_en_400M_v5', 'dunzhang/stella_en_400M_v5', 'dunzhang/stella_en_400M_v5', 'dunzhang/stella_en_400M_v5', 'dunzhang/stella_en_400M_v5', 'dunzhang/stella_en_400M_v5', 'dunzhang/stella_en_400M_v5', 'dunzhang/stella_en_400M_v5', 'dunzhang/stella_en_400M_v5', 'dunzhang/stella_en_400M_v5', 'dunzhang/stella_en_400M_v5', 'dunzhang/stella_en_400M_v5', 'dunzhang/stella_en_400M_v5', 'dunzhang/stella_en_400M_v5', 'dunzhang/stella_en_400M_v5', 'dunzhang/stella_en_400M_v5', 'llmrails/ember-v1', 'llmrails/ember-v1', 'llmrails/ember-v1', 'llmrails/ember-v1', 'llmrails/ember-v1', 'llmrails/ember-v1', 'llmrails/ember-v1', 'llmrails/ember-v1', 'llmrails/ember-v1', 'llmrails/ember-v1', 'llmrails/ember-v1', 'llmrails/ember-v1', 'llmrails/ember-v1', 'llmrails/ember-v1', 'llmrails/ember-v1', 'llmrails/ember-v1', 'llmrails/ember-v1', 'llmrails/ember-v1', 'llmrails/ember-v1', 'llmrails/ember-v1', 'WhereIsAI/UAE-Large-V1', 'WhereIsAI/UAE-Large-V1', 'WhereIsAI/UAE-Large-V1', 'WhereIsAI/UAE-Large-V1', 'WhereIsAI/UAE-Large-V1', 'WhereIsAI/UAE-Large-V1', 'WhereIsAI/UAE-Large-V1', 'WhereIsAI/UAE-Large-V1', 'WhereIsAI/UAE-Large-V1', 'WhereIsAI/UAE-Large-V1', 'WhereIsAI/UAE-Large-V1', 'WhereIsAI/UAE-Large-V1', 'WhereIsAI/UAE-Large-V1', 'WhereIsAI/UAE-Large-V1', 'WhereIsAI/UAE-Large-V1', 'WhereIsAI/UAE-Large-V1', 'WhereIsAI/UAE-Large-V1', 'WhereIsAI/UAE-Large-V1', 'WhereIsAI/UAE-Large-V1', 'WhereIsAI/UAE-Large-V1', 'infgrad/stella-base-en-v2', 'infgrad/stella-base-en-v2', 'infgrad/stella-base-en-v2', 'infgrad/stella-base-en-v2', 'infgrad/stella-base-en-v2', 'infgrad/stella-base-en-v2', 'infgrad/stella-base-en-v2', 'infgrad/stella-base-en-v2', 'infgrad/stella-base-en-v2', 'infgrad/stella-base-en-v2', 'infgrad/stella-base-en-v2', 'infgrad/stella-base-en-v2', 'infgrad/stella-base-en-v2', 'infgrad/stella-base-en-v2', 'infgrad/stella-base-en-v2', 'infgrad/stella-base-en-v2', 'infgrad/stella-base-en-v2', 'infgrad/stella-base-en-v2', 'infgrad/stella-base-en-v2', 'infgrad/stella-base-en-v2', 'intfloat/e5-small', 'intfloat/e5-small', 'intfloat/e5-small', 'intfloat/e5-small', 'intfloat/e5-small', 'intfloat/e5-small', 'intfloat/e5-small', 'intfloat/e5-small', 'intfloat/e5-small', 'intfloat/e5-small', 'intfloat/e5-small', 'intfloat/e5-small', 'intfloat/e5-small', 'intfloat/e5-small', 'intfloat/e5-small', 'intfloat/e5-small', 'intfloat/e5-small', 'intfloat/e5-small', 'intfloat/e5-small', 'intfloat/e5-small', 'BAAI/bge-small-en-v1.5', 'BAAI/bge-small-en-v1.5', 'BAAI/bge-small-en-v1.5', 'BAAI/bge-small-en-v1.5', 'BAAI/bge-small-en-v1.5', 'BAAI/bge-small-en-v1.5', 'BAAI/bge-small-en-v1.5', 'BAAI/bge-small-en-v1.5', 'BAAI/bge-small-en-v1.5', 'BAAI/bge-small-en-v1.5', 'BAAI/bge-small-en-v1.5', 'BAAI/bge-small-en-v1.5', 'BAAI/bge-small-en-v1.5', 'BAAI/bge-small-en-v1.5', 'BAAI/bge-small-en-v1.5', 'BAAI/bge-small-en-v1.5', 'BAAI/bge-small-en-v1.5', 'BAAI/bge-small-en-v1.5', 'BAAI/bge-small-en-v1.5', 'BAAI/bge-small-en-v1.5', 'dunzhang/stella_en_1.5B_v5', 'dunzhang/stella_en_1.5B_v5', 'dunzhang/stella_en_1.5B_v5', 'dunzhang/stella_en_1.5B_v5', 'dunzhang/stella_en_1.5B_v5', 'dunzhang/stella_en_1.5B_v5', 'dunzhang/stella_en_1.5B_v5', 'dunzhang/stella_en_1.5B_v5', 'dunzhang/stella_en_1.5B_v5', 'dunzhang/stella_en_1.5B_v5', 'dunzhang/stella_en_1.5B_v5', 'dunzhang/stella_en_1.5B_v5', 'dunzhang/stella_en_1.5B_v5', 'dunzhang/stella_en_1.5B_v5', 'dunzhang/stella_en_1.5B_v5', 'dunzhang/stella_en_1.5B_v5', 'dunzhang/stella_en_1.5B_v5', 'dunzhang/stella_en_1.5B_v5', 'dunzhang/stella_en_1.5B_v5', 'dunzhang/stella_en_1.5B_v5', 'BAAI/bge-en-icl', 'BAAI/bge-en-icl', 'BAAI/bge-en-icl', 'BAAI/bge-en-icl', 'BAAI/bge-en-icl', 'BAAI/bge-en-icl', 'BAAI/bge-en-icl', 'BAAI/bge-en-icl', 'BAAI/bge-en-icl', 'BAAI/bge-en-icl', 'BAAI/bge-en-icl', 'BAAI/bge-en-icl', 'BAAI/bge-en-icl', 'BAAI/bge-en-icl', 'BAAI/bge-en-icl', 'BAAI/bge-en-icl', 'BAAI/bge-en-icl', 'BAAI/bge-en-icl', 'BAAI/bge-en-icl', 'BAAI/bge-en-icl', 'blevlabs/stella_en_v5', 'blevlabs/stella_en_v5', 'blevlabs/stella_en_v5', 'blevlabs/stella_en_v5', 'blevlabs/stella_en_v5', 'blevlabs/stella_en_v5', 'blevlabs/stella_en_v5', 'blevlabs/stella_en_v5', 'blevlabs/stella_en_v5', 'blevlabs/stella_en_v5', 'blevlabs/stella_en_v5', 'blevlabs/stella_en_v5', 'blevlabs/stella_en_v5', 'blevlabs/stella_en_v5', 'blevlabs/stella_en_v5', 'blevlabs/stella_en_v5', 'blevlabs/stella_en_v5', 'blevlabs/stella_en_v5', 'blevlabs/stella_en_v5', 'blevlabs/stella_en_v5', 'Salesforce/SFR-Embedding-2_R', 'Salesforce/SFR-Embedding-2_R', 'Salesforce/SFR-Embedding-2_R', 'Salesforce/SFR-Embedding-2_R', 'Salesforce/SFR-Embedding-2_R', 'Salesforce/SFR-Embedding-2_R', 'Salesforce/SFR-Embedding-2_R', 'Salesforce/SFR-Embedding-2_R', 'Salesforce/SFR-Embedding-2_R', 'Salesforce/SFR-Embedding-2_R', 'Salesforce/SFR-Embedding-2_R', 'Salesforce/SFR-Embedding-2_R', 'Salesforce/SFR-Embedding-2_R', 'Salesforce/SFR-Embedding-2_R', 'Salesforce/SFR-Embedding-2_R', 'Salesforce/SFR-Embedding-2_R', 'Salesforce/SFR-Embedding-2_R', 'Salesforce/SFR-Embedding-2_R', 'Salesforce/SFR-Embedding-2_R', 'Salesforce/SFR-Embedding-2_R', 'Lajavaness/bilingual-embedding-large', 'Lajavaness/bilingual-embedding-large', 'Lajavaness/bilingual-embedding-large', 'Lajavaness/bilingual-embedding-large', 'Lajavaness/bilingual-embedding-large', 'Lajavaness/bilingual-embedding-large', 'Lajavaness/bilingual-embedding-large', 'Lajavaness/bilingual-embedding-large', 'Lajavaness/bilingual-embedding-large', 'Lajavaness/bilingual-embedding-large', 'Lajavaness/bilingual-embedding-large', 'Lajavaness/bilingual-embedding-large', 'Lajavaness/bilingual-embedding-large', 'Lajavaness/bilingual-embedding-large', 'Lajavaness/bilingual-embedding-large', 'Lajavaness/bilingual-embedding-large', 'Lajavaness/bilingual-embedding-large', 'Lajavaness/bilingual-embedding-large', 'Lajavaness/bilingual-embedding-large', 'Lajavaness/bilingual-embedding-large', 'ilhamdprastyo/jina-embeddings-v3-tei', 'ilhamdprastyo/jina-embeddings-v3-tei', 'ilhamdprastyo/jina-embeddings-v3-tei', 'ilhamdprastyo/jina-embeddings-v3-tei', 'ilhamdprastyo/jina-embeddings-v3-tei', 'ilhamdprastyo/jina-embeddings-v3-tei', 'ilhamdprastyo/jina-embeddings-v3-tei', 'ilhamdprastyo/jina-embeddings-v3-tei', 'ilhamdprastyo/jina-embeddings-v3-tei', 'ilhamdprastyo/jina-embeddings-v3-tei', 'ilhamdprastyo/jina-embeddings-v3-tei', 'ilhamdprastyo/jina-embeddings-v3-tei', 'ilhamdprastyo/jina-embeddings-v3-tei', 'ilhamdprastyo/jina-embeddings-v3-tei', 'ilhamdprastyo/jina-embeddings-v3-tei', 'ilhamdprastyo/jina-embeddings-v3-tei', 'ilhamdprastyo/jina-embeddings-v3-tei', 'ilhamdprastyo/jina-embeddings-v3-tei', 'ilhamdprastyo/jina-embeddings-v3-tei', 'ilhamdprastyo/jina-embeddings-v3-tei', 'jinaai/jina-embeddings-v3', 'jinaai/jina-embeddings-v3', 'jinaai/jina-embeddings-v3', 'jinaai/jina-embeddings-v3', 'jinaai/jina-embeddings-v3', 'jinaai/jina-embeddings-v3', 'jinaai/jina-embeddings-v3', 'jinaai/jina-embeddings-v3', 'jinaai/jina-embeddings-v3', 'jinaai/jina-embeddings-v3', 'jinaai/jina-embeddings-v3', 'jinaai/jina-embeddings-v3', 'jinaai/jina-embeddings-v3', 'jinaai/jina-embeddings-v3', 'jinaai/jina-embeddings-v3', 'jinaai/jina-embeddings-v3', 'jinaai/jina-embeddings-v3', 'jinaai/jina-embeddings-v3', 'jinaai/jina-embeddings-v3', 'jinaai/jina-embeddings-v3']\n",
      "['86', '89', '90', '90', '91', '91', '92', '92', '94', '93', '93', '94', '93', '92', '91', '90', '90', '100', '100', '100', '86', '89', '90', '90', '91', '91', '92', '92', '94', '93', '93', '94', '93', '92', '91', '90', '90', '100', '100', '100', '89', '91', '91', '90', '92', '91', '91', '90', '94', '93', '92', '91', '91', '95', '95', '95', '94', '100', '100', '100', '92', '91', '94', '93', '93', '93', '93', '92', '92', '91', '90', '90', '94', '94', '94', '100', '100', '100', '100', '100', '94', '94', '93', '93', '93', '92', '92', '92', '91', '91', '95', '94', '94', '94', '100', '100', '100', '100', '100', '100', '87', '87', '88', '90', '89', '89', '89', '94', '94', '93', '92', '91', '91', '91', '94', '94', '94', '100', '100', '100', '79', '79', '79', '80', '81', '82', '84', '84', '85', '89', '90', '89', '88', '89', '91', '90', '90', '94', '94', '100', '88', '88', '88', '87', '88', '89', '87', '90', '89', '93', '92', '91', '89', '88', '88', '93', '100', '100', '100', '100', '88', '87', '89', '89', '88', '88', '87', '88', '88', '93', '93', '92', '92', '91', '95', '94', '94', '100', '100', '100', '93', '96', '95', '98', '98', '100', '100', '100', '100', '100', '100', '100', '100', '100', '100', '100', '100', '100', '100', '100', '88', '87', '89', '89', '88', '88', '87', '88', '88', '93', '93', '92', '92', '91', '95', '94', '94', '100', '100', '100', '90', '90', '91', '91', '90', '92', '92', '91', '91', '90', '92', '93', '95', '94', '93', '91', '89', '100', '100', '100', '92', '92', '91', '91', '91', '93', '96', '96', '100', '100', '100', '100', '100', '100', '100', '100', '100', '100', '100', '100', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '92', '92', '93', '95', '94', '94', '94', '93', '93', '91', '91', '89', '89', '89', '89', '100', '100', '100', '100', '100']\n",
      "['0.8', '0.81', '0.82', '0.83', '0.84', '0.85', '0.86', '0.87', '0.88', '0.89', '0.9', '0.91', '0.92', '0.93', '0.94', '0.95', '0.96', '0.97', '0.98', '0.99', '0.8', '0.81', '0.82', '0.83', '0.84', '0.85', '0.86', '0.87', '0.88', '0.89', '0.9', '0.91', '0.92', '0.93', '0.94', '0.95', '0.96', '0.97', '0.98', '0.99', '0.8', '0.81', '0.82', '0.83', '0.84', '0.85', '0.86', '0.87', '0.88', '0.89', '0.9', '0.91', '0.92', '0.93', '0.94', '0.95', '0.96', '0.97', '0.98', '0.99', '0.8', '0.81', '0.82', '0.83', '0.84', '0.85', '0.86', '0.87', '0.88', '0.89', '0.9', '0.91', '0.92', '0.93', '0.94', '0.95', '0.96', '0.97', '0.98', '0.99', '0.8', '0.81', '0.82', '0.83', '0.84', '0.85', '0.86', '0.87', '0.88', '0.89', '0.9', '0.91', '0.92', '0.93', '0.94', '0.95', '0.96', '0.97', '0.98', '0.99', '0.8', '0.81', '0.82', '0.83', '0.84', '0.85', '0.86', '0.87', '0.88', '0.89', '0.9', '0.91', '0.92', '0.93', '0.94', '0.95', '0.96', '0.97', '0.98', '0.99', '0.8', '0.81', '0.82', '0.83', '0.84', '0.85', '0.86', '0.87', '0.88', '0.89', '0.9', '0.91', '0.92', '0.93', '0.94', '0.95', '0.96', '0.97', '0.98', '0.99', '0.8', '0.81', '0.82', '0.83', '0.84', '0.85', '0.86', '0.87', '0.88', '0.89', '0.9', '0.91', '0.92', '0.93', '0.94', '0.95', '0.96', '0.97', '0.98', '0.99', '0.8', '0.81', '0.82', '0.83', '0.84', '0.85', '0.86', '0.87', '0.88', '0.89', '0.9', '0.91', '0.92', '0.93', '0.94', '0.95', '0.96', '0.97', '0.98', '0.99', '0.8', '0.81', '0.82', '0.83', '0.84', '0.85', '0.86', '0.87', '0.88', '0.89', '0.9', '0.91', '0.92', '0.93', '0.94', '0.95', '0.96', '0.97', '0.98', '0.99', '0.8', '0.81', '0.82', '0.83', '0.84', '0.85', '0.86', '0.87', '0.88', '0.89', '0.9', '0.91', '0.92', '0.93', '0.94', '0.95', '0.96', '0.97', '0.98', '0.99', '0.8', '0.81', '0.82', '0.83', '0.84', '0.85', '0.86', '0.87', '0.88', '0.89', '0.9', '0.91', '0.92', '0.93', '0.94', '0.95', '0.96', '0.97', '0.98', '0.99', '0.8', '0.81', '0.82', '0.83', '0.84', '0.85', '0.86', '0.87', '0.88', '0.89', '0.9', '0.91', '0.92', '0.93', '0.94', '0.95', '0.96', '0.97', '0.98', '0.99', '0.8', '0.81', '0.82', '0.83', '0.84', '0.85', '0.86', '0.87', '0.88', '0.89', '0.9', '0.91', '0.92', '0.93', '0.94', '0.95', '0.96', '0.97', '0.98', '0.99', '0.8', '0.81', '0.82', '0.83', '0.84', '0.85', '0.86', '0.87', '0.88', '0.89', '0.9', '0.91', '0.92', '0.93', '0.94', '0.95', '0.96', '0.97', '0.98', '0.99']\n",
      "{'Salesforce/SFR-Embedding-Mistral': ['0.88', '94'], 'compressa-ai/Compressa-Embeddings': ['0.88', '94'], 'dunzhang/stella_en_400M_v5': ['0.93', '95'], 'llmrails/ember-v1': ['0.82', '94'], 'WhereIsAI/UAE-Large-V1': ['0.9', '95'], 'infgrad/stella-base-en-v2': ['0.87', '94'], 'intfloat/e5-small': ['0.97', '94'], 'BAAI/bge-small-en-v1.5': ['0.89', '93'], 'dunzhang/stella_en_1.5B_v5': ['0.94', '95'], 'BAAI/bge-en-icl': ['0.83', '98'], 'blevlabs/stella_en_v5': ['0.94', '95'], 'Salesforce/SFR-Embedding-2_R': ['0.92', '95'], 'Lajavaness/bilingual-embedding-large': ['0.86', '96'], 'ilhamdprastyo/jina-embeddings-v3-tei': ['0.8', '0'], 'jinaai/jina-embeddings-v3': ['0.83', '95']}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c37ec593d0f34669822e45061a8ce34b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c68d75c730f94aaeb3acba23c146b6ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47f72df3f1314a0ca9f960b5c8c3e697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2417f01c985a4a69ac5d6b9b8688b389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A matching Triton is not available, some optimizations will not be enabled\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/gzedda/miniconda3/envs/ambientez/lib/python3.13/site-packages/xformers/__init__.py\", line 57, in _is_triton_available\n",
      "    import triton  # noqa\n",
      "    ^^^^^^^^^^^^^\n",
      "ModuleNotFoundError: No module named 'triton'\n",
      "Some weights of the model checkpoint at dunzhang/stella_en_400M_v5 were not used when initializing NewModel: ['new.pooler.dense.bias', 'new.pooler.dense.weight']\n",
      "- This IS expected if you are initializing NewModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing NewModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at dunzhang/stella_en_400M_v5 were not used when initializing NewModel: ['new.pooler.dense.bias', 'new.pooler.dense.weight']\n",
      "- This IS expected if you are initializing NewModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing NewModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "No sentence-transformers model found with name infgrad/stella-base-en-v2. Creating a new one with mean pooling.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "No sentence-transformers model found with name BAAI/bge-en-icl. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c52ebd2953e4b8a8acd0aeeb2fbc6b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db0b49977ffc4eeba5e3c9d4bafad252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4fde196f70541c196dfcff6f130ecfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b68b1e27a2ac4be8b21d553536ba9665",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "Some weights of XLMRobertaLoRA were not initialized from the model checkpoint at ilhamdprastyo/jina-embeddings-v3-tei and are newly initialized: ['roberta.embeddings.position_embeddings.parametrizations.weight.0.lora_A', 'roberta.embeddings.position_embeddings.parametrizations.weight.0.lora_B', 'roberta.embeddings.position_embeddings.parametrizations.weight.original']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at ilhamdprastyo/jina-embeddings-v3-tei were not used when initializing XLMRobertaModel: ['roberta.emb_ln.bias', 'roberta.emb_ln.weight', 'roberta.embeddings.token_type_embeddings.parametrizations.weight.0.lora_A', 'roberta.embeddings.token_type_embeddings.parametrizations.weight.0.lora_B', 'roberta.embeddings.token_type_embeddings.parametrizations.weight.original', 'roberta.embeddings.word_embeddings.parametrizations.weight.0.lora_A', 'roberta.embeddings.word_embeddings.parametrizations.weight.0.lora_B', 'roberta.embeddings.word_embeddings.parametrizations.weight.original', 'roberta.encoder.layers.0.mixer.Wqkv.bias', 'roberta.encoder.layers.0.mixer.Wqkv.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.0.mixer.Wqkv.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.0.mixer.Wqkv.parametrizations.weight.original', 'roberta.encoder.layers.0.mixer.out_proj.bias', 'roberta.encoder.layers.0.mixer.out_proj.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.0.mixer.out_proj.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.0.mixer.out_proj.parametrizations.weight.original', 'roberta.encoder.layers.0.mlp.fc1.bias', 'roberta.encoder.layers.0.mlp.fc1.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.0.mlp.fc1.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.0.mlp.fc1.parametrizations.weight.original', 'roberta.encoder.layers.0.mlp.fc2.bias', 'roberta.encoder.layers.0.mlp.fc2.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.0.mlp.fc2.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.0.mlp.fc2.parametrizations.weight.original', 'roberta.encoder.layers.0.norm1.bias', 'roberta.encoder.layers.0.norm1.weight', 'roberta.encoder.layers.0.norm2.bias', 'roberta.encoder.layers.0.norm2.weight', 'roberta.encoder.layers.1.mixer.Wqkv.bias', 'roberta.encoder.layers.1.mixer.Wqkv.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.1.mixer.Wqkv.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.1.mixer.Wqkv.parametrizations.weight.original', 'roberta.encoder.layers.1.mixer.out_proj.bias', 'roberta.encoder.layers.1.mixer.out_proj.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.1.mixer.out_proj.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.1.mixer.out_proj.parametrizations.weight.original', 'roberta.encoder.layers.1.mlp.fc1.bias', 'roberta.encoder.layers.1.mlp.fc1.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.1.mlp.fc1.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.1.mlp.fc1.parametrizations.weight.original', 'roberta.encoder.layers.1.mlp.fc2.bias', 'roberta.encoder.layers.1.mlp.fc2.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.1.mlp.fc2.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.1.mlp.fc2.parametrizations.weight.original', 'roberta.encoder.layers.1.norm1.bias', 'roberta.encoder.layers.1.norm1.weight', 'roberta.encoder.layers.1.norm2.bias', 'roberta.encoder.layers.1.norm2.weight', 'roberta.encoder.layers.10.mixer.Wqkv.bias', 'roberta.encoder.layers.10.mixer.Wqkv.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.10.mixer.Wqkv.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.10.mixer.Wqkv.parametrizations.weight.original', 'roberta.encoder.layers.10.mixer.out_proj.bias', 'roberta.encoder.layers.10.mixer.out_proj.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.10.mixer.out_proj.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.10.mixer.out_proj.parametrizations.weight.original', 'roberta.encoder.layers.10.mlp.fc1.bias', 'roberta.encoder.layers.10.mlp.fc1.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.10.mlp.fc1.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.10.mlp.fc1.parametrizations.weight.original', 'roberta.encoder.layers.10.mlp.fc2.bias', 'roberta.encoder.layers.10.mlp.fc2.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.10.mlp.fc2.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.10.mlp.fc2.parametrizations.weight.original', 'roberta.encoder.layers.10.norm1.bias', 'roberta.encoder.layers.10.norm1.weight', 'roberta.encoder.layers.10.norm2.bias', 'roberta.encoder.layers.10.norm2.weight', 'roberta.encoder.layers.11.mixer.Wqkv.bias', 'roberta.encoder.layers.11.mixer.Wqkv.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.11.mixer.Wqkv.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.11.mixer.Wqkv.parametrizations.weight.original', 'roberta.encoder.layers.11.mixer.out_proj.bias', 'roberta.encoder.layers.11.mixer.out_proj.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.11.mixer.out_proj.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.11.mixer.out_proj.parametrizations.weight.original', 'roberta.encoder.layers.11.mlp.fc1.bias', 'roberta.encoder.layers.11.mlp.fc1.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.11.mlp.fc1.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.11.mlp.fc1.parametrizations.weight.original', 'roberta.encoder.layers.11.mlp.fc2.bias', 'roberta.encoder.layers.11.mlp.fc2.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.11.mlp.fc2.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.11.mlp.fc2.parametrizations.weight.original', 'roberta.encoder.layers.11.norm1.bias', 'roberta.encoder.layers.11.norm1.weight', 'roberta.encoder.layers.11.norm2.bias', 'roberta.encoder.layers.11.norm2.weight', 'roberta.encoder.layers.12.mixer.Wqkv.bias', 'roberta.encoder.layers.12.mixer.Wqkv.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.12.mixer.Wqkv.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.12.mixer.Wqkv.parametrizations.weight.original', 'roberta.encoder.layers.12.mixer.out_proj.bias', 'roberta.encoder.layers.12.mixer.out_proj.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.12.mixer.out_proj.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.12.mixer.out_proj.parametrizations.weight.original', 'roberta.encoder.layers.12.mlp.fc1.bias', 'roberta.encoder.layers.12.mlp.fc1.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.12.mlp.fc1.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.12.mlp.fc1.parametrizations.weight.original', 'roberta.encoder.layers.12.mlp.fc2.bias', 'roberta.encoder.layers.12.mlp.fc2.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.12.mlp.fc2.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.12.mlp.fc2.parametrizations.weight.original', 'roberta.encoder.layers.12.norm1.bias', 'roberta.encoder.layers.12.norm1.weight', 'roberta.encoder.layers.12.norm2.bias', 'roberta.encoder.layers.12.norm2.weight', 'roberta.encoder.layers.13.mixer.Wqkv.bias', 'roberta.encoder.layers.13.mixer.Wqkv.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.13.mixer.Wqkv.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.13.mixer.Wqkv.parametrizations.weight.original', 'roberta.encoder.layers.13.mixer.out_proj.bias', 'roberta.encoder.layers.13.mixer.out_proj.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.13.mixer.out_proj.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.13.mixer.out_proj.parametrizations.weight.original', 'roberta.encoder.layers.13.mlp.fc1.bias', 'roberta.encoder.layers.13.mlp.fc1.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.13.mlp.fc1.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.13.mlp.fc1.parametrizations.weight.original', 'roberta.encoder.layers.13.mlp.fc2.bias', 'roberta.encoder.layers.13.mlp.fc2.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.13.mlp.fc2.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.13.mlp.fc2.parametrizations.weight.original', 'roberta.encoder.layers.13.norm1.bias', 'roberta.encoder.layers.13.norm1.weight', 'roberta.encoder.layers.13.norm2.bias', 'roberta.encoder.layers.13.norm2.weight', 'roberta.encoder.layers.14.mixer.Wqkv.bias', 'roberta.encoder.layers.14.mixer.Wqkv.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.14.mixer.Wqkv.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.14.mixer.Wqkv.parametrizations.weight.original', 'roberta.encoder.layers.14.mixer.out_proj.bias', 'roberta.encoder.layers.14.mixer.out_proj.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.14.mixer.out_proj.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.14.mixer.out_proj.parametrizations.weight.original', 'roberta.encoder.layers.14.mlp.fc1.bias', 'roberta.encoder.layers.14.mlp.fc1.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.14.mlp.fc1.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.14.mlp.fc1.parametrizations.weight.original', 'roberta.encoder.layers.14.mlp.fc2.bias', 'roberta.encoder.layers.14.mlp.fc2.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.14.mlp.fc2.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.14.mlp.fc2.parametrizations.weight.original', 'roberta.encoder.layers.14.norm1.bias', 'roberta.encoder.layers.14.norm1.weight', 'roberta.encoder.layers.14.norm2.bias', 'roberta.encoder.layers.14.norm2.weight', 'roberta.encoder.layers.15.mixer.Wqkv.bias', 'roberta.encoder.layers.15.mixer.Wqkv.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.15.mixer.Wqkv.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.15.mixer.Wqkv.parametrizations.weight.original', 'roberta.encoder.layers.15.mixer.out_proj.bias', 'roberta.encoder.layers.15.mixer.out_proj.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.15.mixer.out_proj.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.15.mixer.out_proj.parametrizations.weight.original', 'roberta.encoder.layers.15.mlp.fc1.bias', 'roberta.encoder.layers.15.mlp.fc1.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.15.mlp.fc1.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.15.mlp.fc1.parametrizations.weight.original', 'roberta.encoder.layers.15.mlp.fc2.bias', 'roberta.encoder.layers.15.mlp.fc2.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.15.mlp.fc2.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.15.mlp.fc2.parametrizations.weight.original', 'roberta.encoder.layers.15.norm1.bias', 'roberta.encoder.layers.15.norm1.weight', 'roberta.encoder.layers.15.norm2.bias', 'roberta.encoder.layers.15.norm2.weight', 'roberta.encoder.layers.16.mixer.Wqkv.bias', 'roberta.encoder.layers.16.mixer.Wqkv.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.16.mixer.Wqkv.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.16.mixer.Wqkv.parametrizations.weight.original', 'roberta.encoder.layers.16.mixer.out_proj.bias', 'roberta.encoder.layers.16.mixer.out_proj.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.16.mixer.out_proj.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.16.mixer.out_proj.parametrizations.weight.original', 'roberta.encoder.layers.16.mlp.fc1.bias', 'roberta.encoder.layers.16.mlp.fc1.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.16.mlp.fc1.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.16.mlp.fc1.parametrizations.weight.original', 'roberta.encoder.layers.16.mlp.fc2.bias', 'roberta.encoder.layers.16.mlp.fc2.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.16.mlp.fc2.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.16.mlp.fc2.parametrizations.weight.original', 'roberta.encoder.layers.16.norm1.bias', 'roberta.encoder.layers.16.norm1.weight', 'roberta.encoder.layers.16.norm2.bias', 'roberta.encoder.layers.16.norm2.weight', 'roberta.encoder.layers.17.mixer.Wqkv.bias', 'roberta.encoder.layers.17.mixer.Wqkv.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.17.mixer.Wqkv.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.17.mixer.Wqkv.parametrizations.weight.original', 'roberta.encoder.layers.17.mixer.out_proj.bias', 'roberta.encoder.layers.17.mixer.out_proj.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.17.mixer.out_proj.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.17.mixer.out_proj.parametrizations.weight.original', 'roberta.encoder.layers.17.mlp.fc1.bias', 'roberta.encoder.layers.17.mlp.fc1.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.17.mlp.fc1.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.17.mlp.fc1.parametrizations.weight.original', 'roberta.encoder.layers.17.mlp.fc2.bias', 'roberta.encoder.layers.17.mlp.fc2.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.17.mlp.fc2.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.17.mlp.fc2.parametrizations.weight.original', 'roberta.encoder.layers.17.norm1.bias', 'roberta.encoder.layers.17.norm1.weight', 'roberta.encoder.layers.17.norm2.bias', 'roberta.encoder.layers.17.norm2.weight', 'roberta.encoder.layers.18.mixer.Wqkv.bias', 'roberta.encoder.layers.18.mixer.Wqkv.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.18.mixer.Wqkv.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.18.mixer.Wqkv.parametrizations.weight.original', 'roberta.encoder.layers.18.mixer.out_proj.bias', 'roberta.encoder.layers.18.mixer.out_proj.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.18.mixer.out_proj.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.18.mixer.out_proj.parametrizations.weight.original', 'roberta.encoder.layers.18.mlp.fc1.bias', 'roberta.encoder.layers.18.mlp.fc1.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.18.mlp.fc1.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.18.mlp.fc1.parametrizations.weight.original', 'roberta.encoder.layers.18.mlp.fc2.bias', 'roberta.encoder.layers.18.mlp.fc2.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.18.mlp.fc2.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.18.mlp.fc2.parametrizations.weight.original', 'roberta.encoder.layers.18.norm1.bias', 'roberta.encoder.layers.18.norm1.weight', 'roberta.encoder.layers.18.norm2.bias', 'roberta.encoder.layers.18.norm2.weight', 'roberta.encoder.layers.19.mixer.Wqkv.bias', 'roberta.encoder.layers.19.mixer.Wqkv.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.19.mixer.Wqkv.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.19.mixer.Wqkv.parametrizations.weight.original', 'roberta.encoder.layers.19.mixer.out_proj.bias', 'roberta.encoder.layers.19.mixer.out_proj.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.19.mixer.out_proj.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.19.mixer.out_proj.parametrizations.weight.original', 'roberta.encoder.layers.19.mlp.fc1.bias', 'roberta.encoder.layers.19.mlp.fc1.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.19.mlp.fc1.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.19.mlp.fc1.parametrizations.weight.original', 'roberta.encoder.layers.19.mlp.fc2.bias', 'roberta.encoder.layers.19.mlp.fc2.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.19.mlp.fc2.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.19.mlp.fc2.parametrizations.weight.original', 'roberta.encoder.layers.19.norm1.bias', 'roberta.encoder.layers.19.norm1.weight', 'roberta.encoder.layers.19.norm2.bias', 'roberta.encoder.layers.19.norm2.weight', 'roberta.encoder.layers.2.mixer.Wqkv.bias', 'roberta.encoder.layers.2.mixer.Wqkv.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.2.mixer.Wqkv.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.2.mixer.Wqkv.parametrizations.weight.original', 'roberta.encoder.layers.2.mixer.out_proj.bias', 'roberta.encoder.layers.2.mixer.out_proj.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.2.mixer.out_proj.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.2.mixer.out_proj.parametrizations.weight.original', 'roberta.encoder.layers.2.mlp.fc1.bias', 'roberta.encoder.layers.2.mlp.fc1.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.2.mlp.fc1.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.2.mlp.fc1.parametrizations.weight.original', 'roberta.encoder.layers.2.mlp.fc2.bias', 'roberta.encoder.layers.2.mlp.fc2.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.2.mlp.fc2.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.2.mlp.fc2.parametrizations.weight.original', 'roberta.encoder.layers.2.norm1.bias', 'roberta.encoder.layers.2.norm1.weight', 'roberta.encoder.layers.2.norm2.bias', 'roberta.encoder.layers.2.norm2.weight', 'roberta.encoder.layers.20.mixer.Wqkv.bias', 'roberta.encoder.layers.20.mixer.Wqkv.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.20.mixer.Wqkv.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.20.mixer.Wqkv.parametrizations.weight.original', 'roberta.encoder.layers.20.mixer.out_proj.bias', 'roberta.encoder.layers.20.mixer.out_proj.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.20.mixer.out_proj.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.20.mixer.out_proj.parametrizations.weight.original', 'roberta.encoder.layers.20.mlp.fc1.bias', 'roberta.encoder.layers.20.mlp.fc1.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.20.mlp.fc1.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.20.mlp.fc1.parametrizations.weight.original', 'roberta.encoder.layers.20.mlp.fc2.bias', 'roberta.encoder.layers.20.mlp.fc2.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.20.mlp.fc2.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.20.mlp.fc2.parametrizations.weight.original', 'roberta.encoder.layers.20.norm1.bias', 'roberta.encoder.layers.20.norm1.weight', 'roberta.encoder.layers.20.norm2.bias', 'roberta.encoder.layers.20.norm2.weight', 'roberta.encoder.layers.21.mixer.Wqkv.bias', 'roberta.encoder.layers.21.mixer.Wqkv.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.21.mixer.Wqkv.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.21.mixer.Wqkv.parametrizations.weight.original', 'roberta.encoder.layers.21.mixer.out_proj.bias', 'roberta.encoder.layers.21.mixer.out_proj.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.21.mixer.out_proj.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.21.mixer.out_proj.parametrizations.weight.original', 'roberta.encoder.layers.21.mlp.fc1.bias', 'roberta.encoder.layers.21.mlp.fc1.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.21.mlp.fc1.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.21.mlp.fc1.parametrizations.weight.original', 'roberta.encoder.layers.21.mlp.fc2.bias', 'roberta.encoder.layers.21.mlp.fc2.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.21.mlp.fc2.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.21.mlp.fc2.parametrizations.weight.original', 'roberta.encoder.layers.21.norm1.bias', 'roberta.encoder.layers.21.norm1.weight', 'roberta.encoder.layers.21.norm2.bias', 'roberta.encoder.layers.21.norm2.weight', 'roberta.encoder.layers.22.mixer.Wqkv.bias', 'roberta.encoder.layers.22.mixer.Wqkv.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.22.mixer.Wqkv.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.22.mixer.Wqkv.parametrizations.weight.original', 'roberta.encoder.layers.22.mixer.out_proj.bias', 'roberta.encoder.layers.22.mixer.out_proj.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.22.mixer.out_proj.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.22.mixer.out_proj.parametrizations.weight.original', 'roberta.encoder.layers.22.mlp.fc1.bias', 'roberta.encoder.layers.22.mlp.fc1.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.22.mlp.fc1.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.22.mlp.fc1.parametrizations.weight.original', 'roberta.encoder.layers.22.mlp.fc2.bias', 'roberta.encoder.layers.22.mlp.fc2.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.22.mlp.fc2.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.22.mlp.fc2.parametrizations.weight.original', 'roberta.encoder.layers.22.norm1.bias', 'roberta.encoder.layers.22.norm1.weight', 'roberta.encoder.layers.22.norm2.bias', 'roberta.encoder.layers.22.norm2.weight', 'roberta.encoder.layers.23.mixer.Wqkv.bias', 'roberta.encoder.layers.23.mixer.Wqkv.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.23.mixer.Wqkv.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.23.mixer.Wqkv.parametrizations.weight.original', 'roberta.encoder.layers.23.mixer.out_proj.bias', 'roberta.encoder.layers.23.mixer.out_proj.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.23.mixer.out_proj.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.23.mixer.out_proj.parametrizations.weight.original', 'roberta.encoder.layers.23.mlp.fc1.bias', 'roberta.encoder.layers.23.mlp.fc1.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.23.mlp.fc1.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.23.mlp.fc1.parametrizations.weight.original', 'roberta.encoder.layers.23.mlp.fc2.bias', 'roberta.encoder.layers.23.mlp.fc2.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.23.mlp.fc2.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.23.mlp.fc2.parametrizations.weight.original', 'roberta.encoder.layers.23.norm1.bias', 'roberta.encoder.layers.23.norm1.weight', 'roberta.encoder.layers.23.norm2.bias', 'roberta.encoder.layers.23.norm2.weight', 'roberta.encoder.layers.3.mixer.Wqkv.bias', 'roberta.encoder.layers.3.mixer.Wqkv.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.3.mixer.Wqkv.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.3.mixer.Wqkv.parametrizations.weight.original', 'roberta.encoder.layers.3.mixer.out_proj.bias', 'roberta.encoder.layers.3.mixer.out_proj.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.3.mixer.out_proj.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.3.mixer.out_proj.parametrizations.weight.original', 'roberta.encoder.layers.3.mlp.fc1.bias', 'roberta.encoder.layers.3.mlp.fc1.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.3.mlp.fc1.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.3.mlp.fc1.parametrizations.weight.original', 'roberta.encoder.layers.3.mlp.fc2.bias', 'roberta.encoder.layers.3.mlp.fc2.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.3.mlp.fc2.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.3.mlp.fc2.parametrizations.weight.original', 'roberta.encoder.layers.3.norm1.bias', 'roberta.encoder.layers.3.norm1.weight', 'roberta.encoder.layers.3.norm2.bias', 'roberta.encoder.layers.3.norm2.weight', 'roberta.encoder.layers.4.mixer.Wqkv.bias', 'roberta.encoder.layers.4.mixer.Wqkv.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.4.mixer.Wqkv.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.4.mixer.Wqkv.parametrizations.weight.original', 'roberta.encoder.layers.4.mixer.out_proj.bias', 'roberta.encoder.layers.4.mixer.out_proj.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.4.mixer.out_proj.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.4.mixer.out_proj.parametrizations.weight.original', 'roberta.encoder.layers.4.mlp.fc1.bias', 'roberta.encoder.layers.4.mlp.fc1.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.4.mlp.fc1.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.4.mlp.fc1.parametrizations.weight.original', 'roberta.encoder.layers.4.mlp.fc2.bias', 'roberta.encoder.layers.4.mlp.fc2.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.4.mlp.fc2.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.4.mlp.fc2.parametrizations.weight.original', 'roberta.encoder.layers.4.norm1.bias', 'roberta.encoder.layers.4.norm1.weight', 'roberta.encoder.layers.4.norm2.bias', 'roberta.encoder.layers.4.norm2.weight', 'roberta.encoder.layers.5.mixer.Wqkv.bias', 'roberta.encoder.layers.5.mixer.Wqkv.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.5.mixer.Wqkv.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.5.mixer.Wqkv.parametrizations.weight.original', 'roberta.encoder.layers.5.mixer.out_proj.bias', 'roberta.encoder.layers.5.mixer.out_proj.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.5.mixer.out_proj.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.5.mixer.out_proj.parametrizations.weight.original', 'roberta.encoder.layers.5.mlp.fc1.bias', 'roberta.encoder.layers.5.mlp.fc1.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.5.mlp.fc1.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.5.mlp.fc1.parametrizations.weight.original', 'roberta.encoder.layers.5.mlp.fc2.bias', 'roberta.encoder.layers.5.mlp.fc2.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.5.mlp.fc2.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.5.mlp.fc2.parametrizations.weight.original', 'roberta.encoder.layers.5.norm1.bias', 'roberta.encoder.layers.5.norm1.weight', 'roberta.encoder.layers.5.norm2.bias', 'roberta.encoder.layers.5.norm2.weight', 'roberta.encoder.layers.6.mixer.Wqkv.bias', 'roberta.encoder.layers.6.mixer.Wqkv.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.6.mixer.Wqkv.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.6.mixer.Wqkv.parametrizations.weight.original', 'roberta.encoder.layers.6.mixer.out_proj.bias', 'roberta.encoder.layers.6.mixer.out_proj.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.6.mixer.out_proj.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.6.mixer.out_proj.parametrizations.weight.original', 'roberta.encoder.layers.6.mlp.fc1.bias', 'roberta.encoder.layers.6.mlp.fc1.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.6.mlp.fc1.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.6.mlp.fc1.parametrizations.weight.original', 'roberta.encoder.layers.6.mlp.fc2.bias', 'roberta.encoder.layers.6.mlp.fc2.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.6.mlp.fc2.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.6.mlp.fc2.parametrizations.weight.original', 'roberta.encoder.layers.6.norm1.bias', 'roberta.encoder.layers.6.norm1.weight', 'roberta.encoder.layers.6.norm2.bias', 'roberta.encoder.layers.6.norm2.weight', 'roberta.encoder.layers.7.mixer.Wqkv.bias', 'roberta.encoder.layers.7.mixer.Wqkv.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.7.mixer.Wqkv.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.7.mixer.Wqkv.parametrizations.weight.original', 'roberta.encoder.layers.7.mixer.out_proj.bias', 'roberta.encoder.layers.7.mixer.out_proj.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.7.mixer.out_proj.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.7.mixer.out_proj.parametrizations.weight.original', 'roberta.encoder.layers.7.mlp.fc1.bias', 'roberta.encoder.layers.7.mlp.fc1.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.7.mlp.fc1.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.7.mlp.fc1.parametrizations.weight.original', 'roberta.encoder.layers.7.mlp.fc2.bias', 'roberta.encoder.layers.7.mlp.fc2.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.7.mlp.fc2.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.7.mlp.fc2.parametrizations.weight.original', 'roberta.encoder.layers.7.norm1.bias', 'roberta.encoder.layers.7.norm1.weight', 'roberta.encoder.layers.7.norm2.bias', 'roberta.encoder.layers.7.norm2.weight', 'roberta.encoder.layers.8.mixer.Wqkv.bias', 'roberta.encoder.layers.8.mixer.Wqkv.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.8.mixer.Wqkv.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.8.mixer.Wqkv.parametrizations.weight.original', 'roberta.encoder.layers.8.mixer.out_proj.bias', 'roberta.encoder.layers.8.mixer.out_proj.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.8.mixer.out_proj.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.8.mixer.out_proj.parametrizations.weight.original', 'roberta.encoder.layers.8.mlp.fc1.bias', 'roberta.encoder.layers.8.mlp.fc1.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.8.mlp.fc1.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.8.mlp.fc1.parametrizations.weight.original', 'roberta.encoder.layers.8.mlp.fc2.bias', 'roberta.encoder.layers.8.mlp.fc2.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.8.mlp.fc2.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.8.mlp.fc2.parametrizations.weight.original', 'roberta.encoder.layers.8.norm1.bias', 'roberta.encoder.layers.8.norm1.weight', 'roberta.encoder.layers.8.norm2.bias', 'roberta.encoder.layers.8.norm2.weight', 'roberta.encoder.layers.9.mixer.Wqkv.bias', 'roberta.encoder.layers.9.mixer.Wqkv.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.9.mixer.Wqkv.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.9.mixer.Wqkv.parametrizations.weight.original', 'roberta.encoder.layers.9.mixer.out_proj.bias', 'roberta.encoder.layers.9.mixer.out_proj.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.9.mixer.out_proj.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.9.mixer.out_proj.parametrizations.weight.original', 'roberta.encoder.layers.9.mlp.fc1.bias', 'roberta.encoder.layers.9.mlp.fc1.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.9.mlp.fc1.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.9.mlp.fc1.parametrizations.weight.original', 'roberta.encoder.layers.9.mlp.fc2.bias', 'roberta.encoder.layers.9.mlp.fc2.parametrizations.weight.0.lora_A', 'roberta.encoder.layers.9.mlp.fc2.parametrizations.weight.0.lora_B', 'roberta.encoder.layers.9.mlp.fc2.parametrizations.weight.original', 'roberta.encoder.layers.9.norm1.bias', 'roberta.encoder.layers.9.norm1.weight', 'roberta.encoder.layers.9.norm2.bias', 'roberta.encoder.layers.9.norm2.weight', 'roberta.pooler.dense.parametrizations.weight.0.lora_A', 'roberta.pooler.dense.parametrizations.weight.0.lora_B', 'roberta.pooler.dense.parametrizations.weight.original']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaModel were not initialized from the model checkpoint at ilhamdprastyo/jina-embeddings-v3-tei and are newly initialized: ['roberta.embeddings.LayerNorm.bias', 'roberta.embeddings.LayerNorm.weight', 'roberta.embeddings.position_embeddings.weight', 'roberta.embeddings.token_type_embeddings.weight', 'roberta.embeddings.word_embeddings.weight', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.output.dense.bias', 'roberta.encoder.layer.0.attention.output.dense.weight', 'roberta.encoder.layer.0.attention.self.key.bias', 'roberta.encoder.layer.0.attention.self.key.weight', 'roberta.encoder.layer.0.attention.self.query.bias', 'roberta.encoder.layer.0.attention.self.query.weight', 'roberta.encoder.layer.0.attention.self.value.bias', 'roberta.encoder.layer.0.attention.self.value.weight', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.0.output.dense.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.encoder.layer.1.attention.output.dense.weight', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.10.attention.output.dense.weight', 'roberta.encoder.layer.10.attention.self.key.bias', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.11.attention.self.key.weight', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.11.attention.self.query.weight', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.12.attention.output.LayerNorm.bias', 'roberta.encoder.layer.12.attention.output.LayerNorm.weight', 'roberta.encoder.layer.12.attention.output.dense.bias', 'roberta.encoder.layer.12.attention.output.dense.weight', 'roberta.encoder.layer.12.attention.self.key.bias', 'roberta.encoder.layer.12.attention.self.key.weight', 'roberta.encoder.layer.12.attention.self.query.bias', 'roberta.encoder.layer.12.attention.self.query.weight', 'roberta.encoder.layer.12.attention.self.value.bias', 'roberta.encoder.layer.12.attention.self.value.weight', 'roberta.encoder.layer.12.intermediate.dense.bias', 'roberta.encoder.layer.12.intermediate.dense.weight', 'roberta.encoder.layer.12.output.LayerNorm.bias', 'roberta.encoder.layer.12.output.LayerNorm.weight', 'roberta.encoder.layer.12.output.dense.bias', 'roberta.encoder.layer.12.output.dense.weight', 'roberta.encoder.layer.13.attention.output.LayerNorm.bias', 'roberta.encoder.layer.13.attention.output.LayerNorm.weight', 'roberta.encoder.layer.13.attention.output.dense.bias', 'roberta.encoder.layer.13.attention.output.dense.weight', 'roberta.encoder.layer.13.attention.self.key.bias', 'roberta.encoder.layer.13.attention.self.key.weight', 'roberta.encoder.layer.13.attention.self.query.bias', 'roberta.encoder.layer.13.attention.self.query.weight', 'roberta.encoder.layer.13.attention.self.value.bias', 'roberta.encoder.layer.13.attention.self.value.weight', 'roberta.encoder.layer.13.intermediate.dense.bias', 'roberta.encoder.layer.13.intermediate.dense.weight', 'roberta.encoder.layer.13.output.LayerNorm.bias', 'roberta.encoder.layer.13.output.LayerNorm.weight', 'roberta.encoder.layer.13.output.dense.bias', 'roberta.encoder.layer.13.output.dense.weight', 'roberta.encoder.layer.14.attention.output.LayerNorm.bias', 'roberta.encoder.layer.14.attention.output.LayerNorm.weight', 'roberta.encoder.layer.14.attention.output.dense.bias', 'roberta.encoder.layer.14.attention.output.dense.weight', 'roberta.encoder.layer.14.attention.self.key.bias', 'roberta.encoder.layer.14.attention.self.key.weight', 'roberta.encoder.layer.14.attention.self.query.bias', 'roberta.encoder.layer.14.attention.self.query.weight', 'roberta.encoder.layer.14.attention.self.value.bias', 'roberta.encoder.layer.14.attention.self.value.weight', 'roberta.encoder.layer.14.intermediate.dense.bias', 'roberta.encoder.layer.14.intermediate.dense.weight', 'roberta.encoder.layer.14.output.LayerNorm.bias', 'roberta.encoder.layer.14.output.LayerNorm.weight', 'roberta.encoder.layer.14.output.dense.bias', 'roberta.encoder.layer.14.output.dense.weight', 'roberta.encoder.layer.15.attention.output.LayerNorm.bias', 'roberta.encoder.layer.15.attention.output.LayerNorm.weight', 'roberta.encoder.layer.15.attention.output.dense.bias', 'roberta.encoder.layer.15.attention.output.dense.weight', 'roberta.encoder.layer.15.attention.self.key.bias', 'roberta.encoder.layer.15.attention.self.key.weight', 'roberta.encoder.layer.15.attention.self.query.bias', 'roberta.encoder.layer.15.attention.self.query.weight', 'roberta.encoder.layer.15.attention.self.value.bias', 'roberta.encoder.layer.15.attention.self.value.weight', 'roberta.encoder.layer.15.intermediate.dense.bias', 'roberta.encoder.layer.15.intermediate.dense.weight', 'roberta.encoder.layer.15.output.LayerNorm.bias', 'roberta.encoder.layer.15.output.LayerNorm.weight', 'roberta.encoder.layer.15.output.dense.bias', 'roberta.encoder.layer.15.output.dense.weight', 'roberta.encoder.layer.16.attention.output.LayerNorm.bias', 'roberta.encoder.layer.16.attention.output.LayerNorm.weight', 'roberta.encoder.layer.16.attention.output.dense.bias', 'roberta.encoder.layer.16.attention.output.dense.weight', 'roberta.encoder.layer.16.attention.self.key.bias', 'roberta.encoder.layer.16.attention.self.key.weight', 'roberta.encoder.layer.16.attention.self.query.bias', 'roberta.encoder.layer.16.attention.self.query.weight', 'roberta.encoder.layer.16.attention.self.value.bias', 'roberta.encoder.layer.16.attention.self.value.weight', 'roberta.encoder.layer.16.intermediate.dense.bias', 'roberta.encoder.layer.16.intermediate.dense.weight', 'roberta.encoder.layer.16.output.LayerNorm.bias', 'roberta.encoder.layer.16.output.LayerNorm.weight', 'roberta.encoder.layer.16.output.dense.bias', 'roberta.encoder.layer.16.output.dense.weight', 'roberta.encoder.layer.17.attention.output.LayerNorm.bias', 'roberta.encoder.layer.17.attention.output.LayerNorm.weight', 'roberta.encoder.layer.17.attention.output.dense.bias', 'roberta.encoder.layer.17.attention.output.dense.weight', 'roberta.encoder.layer.17.attention.self.key.bias', 'roberta.encoder.layer.17.attention.self.key.weight', 'roberta.encoder.layer.17.attention.self.query.bias', 'roberta.encoder.layer.17.attention.self.query.weight', 'roberta.encoder.layer.17.attention.self.value.bias', 'roberta.encoder.layer.17.attention.self.value.weight', 'roberta.encoder.layer.17.intermediate.dense.bias', 'roberta.encoder.layer.17.intermediate.dense.weight', 'roberta.encoder.layer.17.output.LayerNorm.bias', 'roberta.encoder.layer.17.output.LayerNorm.weight', 'roberta.encoder.layer.17.output.dense.bias', 'roberta.encoder.layer.17.output.dense.weight', 'roberta.encoder.layer.18.attention.output.LayerNorm.bias', 'roberta.encoder.layer.18.attention.output.LayerNorm.weight', 'roberta.encoder.layer.18.attention.output.dense.bias', 'roberta.encoder.layer.18.attention.output.dense.weight', 'roberta.encoder.layer.18.attention.self.key.bias', 'roberta.encoder.layer.18.attention.self.key.weight', 'roberta.encoder.layer.18.attention.self.query.bias', 'roberta.encoder.layer.18.attention.self.query.weight', 'roberta.encoder.layer.18.attention.self.value.bias', 'roberta.encoder.layer.18.attention.self.value.weight', 'roberta.encoder.layer.18.intermediate.dense.bias', 'roberta.encoder.layer.18.intermediate.dense.weight', 'roberta.encoder.layer.18.output.LayerNorm.bias', 'roberta.encoder.layer.18.output.LayerNorm.weight', 'roberta.encoder.layer.18.output.dense.bias', 'roberta.encoder.layer.18.output.dense.weight', 'roberta.encoder.layer.19.attention.output.LayerNorm.bias', 'roberta.encoder.layer.19.attention.output.LayerNorm.weight', 'roberta.encoder.layer.19.attention.output.dense.bias', 'roberta.encoder.layer.19.attention.output.dense.weight', 'roberta.encoder.layer.19.attention.self.key.bias', 'roberta.encoder.layer.19.attention.self.key.weight', 'roberta.encoder.layer.19.attention.self.query.bias', 'roberta.encoder.layer.19.attention.self.query.weight', 'roberta.encoder.layer.19.attention.self.value.bias', 'roberta.encoder.layer.19.attention.self.value.weight', 'roberta.encoder.layer.19.intermediate.dense.bias', 'roberta.encoder.layer.19.intermediate.dense.weight', 'roberta.encoder.layer.19.output.LayerNorm.bias', 'roberta.encoder.layer.19.output.LayerNorm.weight', 'roberta.encoder.layer.19.output.dense.bias', 'roberta.encoder.layer.19.output.dense.weight', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.2.attention.output.dense.weight', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.2.attention.self.query.bias', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.20.attention.output.LayerNorm.bias', 'roberta.encoder.layer.20.attention.output.LayerNorm.weight', 'roberta.encoder.layer.20.attention.output.dense.bias', 'roberta.encoder.layer.20.attention.output.dense.weight', 'roberta.encoder.layer.20.attention.self.key.bias', 'roberta.encoder.layer.20.attention.self.key.weight', 'roberta.encoder.layer.20.attention.self.query.bias', 'roberta.encoder.layer.20.attention.self.query.weight', 'roberta.encoder.layer.20.attention.self.value.bias', 'roberta.encoder.layer.20.attention.self.value.weight', 'roberta.encoder.layer.20.intermediate.dense.bias', 'roberta.encoder.layer.20.intermediate.dense.weight', 'roberta.encoder.layer.20.output.LayerNorm.bias', 'roberta.encoder.layer.20.output.LayerNorm.weight', 'roberta.encoder.layer.20.output.dense.bias', 'roberta.encoder.layer.20.output.dense.weight', 'roberta.encoder.layer.21.attention.output.LayerNorm.bias', 'roberta.encoder.layer.21.attention.output.LayerNorm.weight', 'roberta.encoder.layer.21.attention.output.dense.bias', 'roberta.encoder.layer.21.attention.output.dense.weight', 'roberta.encoder.layer.21.attention.self.key.bias', 'roberta.encoder.layer.21.attention.self.key.weight', 'roberta.encoder.layer.21.attention.self.query.bias', 'roberta.encoder.layer.21.attention.self.query.weight', 'roberta.encoder.layer.21.attention.self.value.bias', 'roberta.encoder.layer.21.attention.self.value.weight', 'roberta.encoder.layer.21.intermediate.dense.bias', 'roberta.encoder.layer.21.intermediate.dense.weight', 'roberta.encoder.layer.21.output.LayerNorm.bias', 'roberta.encoder.layer.21.output.LayerNorm.weight', 'roberta.encoder.layer.21.output.dense.bias', 'roberta.encoder.layer.21.output.dense.weight', 'roberta.encoder.layer.22.attention.output.LayerNorm.bias', 'roberta.encoder.layer.22.attention.output.LayerNorm.weight', 'roberta.encoder.layer.22.attention.output.dense.bias', 'roberta.encoder.layer.22.attention.output.dense.weight', 'roberta.encoder.layer.22.attention.self.key.bias', 'roberta.encoder.layer.22.attention.self.key.weight', 'roberta.encoder.layer.22.attention.self.query.bias', 'roberta.encoder.layer.22.attention.self.query.weight', 'roberta.encoder.layer.22.attention.self.value.bias', 'roberta.encoder.layer.22.attention.self.value.weight', 'roberta.encoder.layer.22.intermediate.dense.bias', 'roberta.encoder.layer.22.intermediate.dense.weight', 'roberta.encoder.layer.22.output.LayerNorm.bias', 'roberta.encoder.layer.22.output.LayerNorm.weight', 'roberta.encoder.layer.22.output.dense.bias', 'roberta.encoder.layer.22.output.dense.weight', 'roberta.encoder.layer.23.attention.output.LayerNorm.bias', 'roberta.encoder.layer.23.attention.output.LayerNorm.weight', 'roberta.encoder.layer.23.attention.output.dense.bias', 'roberta.encoder.layer.23.attention.output.dense.weight', 'roberta.encoder.layer.23.attention.self.key.bias', 'roberta.encoder.layer.23.attention.self.key.weight', 'roberta.encoder.layer.23.attention.self.query.bias', 'roberta.encoder.layer.23.attention.self.query.weight', 'roberta.encoder.layer.23.attention.self.value.bias', 'roberta.encoder.layer.23.attention.self.value.weight', 'roberta.encoder.layer.23.intermediate.dense.bias', 'roberta.encoder.layer.23.intermediate.dense.weight', 'roberta.encoder.layer.23.output.LayerNorm.bias', 'roberta.encoder.layer.23.output.LayerNorm.weight', 'roberta.encoder.layer.23.output.dense.bias', 'roberta.encoder.layer.23.output.dense.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.encoder.layer.3.attention.self.key.weight', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.5.attention.self.query.bias', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.output.dense.bias', 'roberta.encoder.layer.6.attention.output.dense.weight', 'roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.6.attention.self.key.weight', 'roberta.encoder.layer.6.attention.self.query.bias', 'roberta.encoder.layer.6.attention.self.query.weight', 'roberta.encoder.layer.6.attention.self.value.bias', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.encoder.layer.6.intermediate.dense.bias', 'roberta.encoder.layer.6.intermediate.dense.weight', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.output.dense.bias', 'roberta.encoder.layer.7.attention.output.dense.weight', 'roberta.encoder.layer.7.attention.self.key.bias', 'roberta.encoder.layer.7.attention.self.key.weight', 'roberta.encoder.layer.7.attention.self.query.bias', 'roberta.encoder.layer.7.attention.self.query.weight', 'roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.7.attention.self.value.weight', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.7.intermediate.dense.weight', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.output.dense.bias', 'roberta.encoder.layer.8.attention.output.dense.weight', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.8.attention.self.key.weight', 'roberta.encoder.layer.8.attention.self.query.bias', 'roberta.encoder.layer.8.attention.self.query.weight', 'roberta.encoder.layer.8.attention.self.value.bias', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.8.intermediate.dense.weight', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.8.output.dense.bias', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.encoder.layer.9.attention.output.dense.weight', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.9.attention.self.key.weight', 'roberta.encoder.layer.9.attention.self.query.bias', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.encoder.layer.9.attention.self.value.weight', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file created ../csv_file/bert_comparison_on_test_set.csv.\n"
     ]
    }
   ],
   "source": [
    "from entity_linking import read_specified_columns, evaluate_entity_linking_method\n",
    "import csv\n",
    "\n",
    "file_path = \"../csv_file/entity_linking_test_normalized_test.csv\"\n",
    "column_list = [\"off_normalized\", \"foodkg_normalized\"]\n",
    "data = read_specified_columns(file_path, elenco_colonne=column_list, delimiter=\",\")\n",
    "\n",
    "file1_path = \"../csv_file/bert_comparison_validation.csv\"\n",
    "column_list = [\"model_name\", \"threshold\", \"accuracy_on_considered\"]\n",
    "reader = read_specified_columns(file1_path, elenco_colonne=column_list, delimiter=\",\")\n",
    "\n",
    "list_of_models = []\n",
    "list_of_threshold = []\n",
    "list_of_accuracy = []\n",
    "\n",
    "for model, threshold, accuracy in reader:\n",
    "    list_of_models.append(model)\n",
    "    list_of_threshold.append(threshold)\n",
    "    list_of_accuracy.append(accuracy)\n",
    "\n",
    "print(list_of_models)\n",
    "print(list_of_accuracy)\n",
    "print(list_of_threshold)\n",
    "\n",
    "\n",
    "model_threshold_dictionary = {}\n",
    "\n",
    "for model, threshold, accuracy in zip(list_of_models, list_of_threshold, list_of_accuracy):\n",
    "    if model not in model_threshold_dictionary:\n",
    "        model_threshold_dictionary[model] = [threshold, accuracy]\n",
    "    else:\n",
    "        if accuracy > model_threshold_dictionary[model][1]:\n",
    "            model_threshold_dictionary[model] = [threshold, accuracy]\n",
    "\n",
    "print(model_threshold_dictionary)\n",
    "\n",
    "\n",
    "\n",
    "column_names = [\"model_name\", \"vocab_size\", \"number_of_parameters\", \"accuracy\", \"accuracy_on_considered\", \"number_of_TP_and_TN\", \"threshold\", ]\n",
    "\n",
    "output_file = \"../csv_file/bert_comparison_on_test_set.csv\"\n",
    "\n",
    "with open(output_file, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(column_names)\n",
    "    \n",
    "    for model in model_threshold_dictionary.keys():\n",
    "        model_name, vocab_size, number_of_parameters, accuracy, accuracy_considered, number_of_TP_and_TN, threshold = evaluate_entity_linking_method(\n",
    "            data, show_progress=False, model=model, threshold_list=model_threshold_dictionary[model][1]\n",
    "        )\n",
    "        for modelz, vocab_sizez, number_of_parametersz, accuracyz, accuracy_consideredz, number_of_TP_and_TNz, thresholdz,  in zip(model_name, vocab_size, number_of_parameters, accuracy, accuracy_considered, number_of_TP_and_TN, threshold):\n",
    "            writer.writerow([modelz, vocab_sizez, number_of_parametersz, round(accuracyz, 2), round(accuracy_consideredz) , number_of_TP_and_TNz, thresholdz])\n",
    "\n",
    "print(f\"file created {output_file}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ambientez",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
