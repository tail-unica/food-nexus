{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIMILARITY WITH A CLASSIC BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar couples:\n",
      "\n",
      "(Protein brownie mini) --- (brownie) --- Similarity: 0.686\n",
      "(Tablet) --- (rennet tablet) --- Similarity: 0.607\n",
      "(Saucisse a tartiner 170g) --- (hake fillets) --- Similarity: 0.327\n",
      "(Noisettes crues) --- (italian - flavored croutons) --- Similarity: 0.411\n",
      "(Hummus gegrilde groenten) --- (hummus) --- Similarity: 0.606\n",
      "(Land O' Frost Premium Cured Roast Beef) --- (roast beef) --- Similarity: 0.743\n",
      "(pepper jelly) --- (pepper jelly) --- Similarity: 1.000\n",
      "(Whole Chocolate Milk) --- (chocolate milk) --- Similarity: 0.951\n",
      "(Filet de poulet) --- (boneless pork filet) --- Similarity: 0.344\n",
      "(Olivenmix mit Kräuter) --- (olive) --- Similarity: 0.621\n",
      "(Rinder-Hackfleisch) --- (white wine vinegar) --- Similarity: 0.247\n",
      "(ICA i♥eco 12 ekologiska ägg från frigående) --- (red enchilada sauce) --- Similarity: 0.272\n",
      "(Harina de trigo especial reposteria) --- (italian - flavored croutons) --- Similarity: 0.281\n",
      "(Sardines in water) --- (sardines) --- Similarity: 0.873\n",
      "(Oeufs frais) --- (oatmeal) --- Similarity: 0.298\n",
      "(Gelée de piments d’espele) --- (hake fillets) --- Similarity: 0.351\n",
      "(Brente Mandler) --- (hake fillets) --- Similarity: 0.262\n",
      "(Cereal) --- (cereal) --- Similarity: 1.000\n",
      "(5 fűszeres paradicsomszó) --- (tzatziki) --- Similarity: 0.307\n",
      "(Jambon traditionnel) --- (red enchilada sauce) --- Similarity: 0.313\n",
      "(Hershey’s cookies ´n’ ) --- (cookies) --- Similarity: 0.702\n",
      "(Salsiccia luganega) --- (salami) --- Similarity: 0.384\n",
      "(Ceviche tilapia) --- (tilapia fillet) --- Similarity: 0.697\n",
      "(Olive oil) --- (olive oil) --- Similarity: 1.000\n",
      "(Fraises) --- (red enchilada sauce) --- Similarity: 0.243\n",
      "(Rillette de Bar Poivre rouge de Kampot) --- (chocolate bar) --- Similarity: 0.311\n",
      "(Export Sodas) --- (7 - Up soda) --- Similarity: 0.598\n",
      "(Vitalis light croccante chioccolato) --- (italian - flavored croutons) --- Similarity: 0.342\n",
      "(Pizza forno de pedra 4 estaçõ) --- (frozen pizza) --- Similarity: 0.470\n",
      "(Nougat Limoncello) --- (limoncello) --- Similarity: 0.768\n",
      "(Glace noisette) --- (tzatziki) --- Similarity: 0.286\n",
      "(Suppennudeln OFFEN) --- (prune) --- Similarity: 0.367\n",
      "(Organic lemons) --- (lemons) --- Similarity: 0.879\n",
      "(Speck alto adige Igp) --- (speck ) --- Similarity: 0.480\n",
      "(Melange d olives) --- (olive) --- Similarity: 0.721\n",
      "(Bens original riz basmati) --- (basmati rice) --- Similarity: 0.372\n",
      "(Emprésuré chocolat inten) --- (hake fillets) --- Similarity: 0.351\n",
      "(Provolone dolce) --- (provolone cheese) --- Similarity: 0.721\n",
      "(Gluten free italian crostini) --- (italian - flavored croutons) --- Similarity: 0.541\n",
      "(Fave Intere Salate) --- (salami) --- Similarity: 0.509\n",
      "(Slightly Salted Butter) --- (lightly - salted butter) --- Similarity: 0.927\n",
      "(Iogurte de Açaí com Banana - Frutap - Frut) --- (banana yogurt) --- Similarity: 0.719\n",
      "(Labeyrie tranches de saumon fum�) --- (raw cacao powder) --- Similarity: 0.341\n",
      "(Sensational Burger) --- (hamburger) --- Similarity: 0.700\n",
      "(Habanero Lime Cream Cheese Wontons) --- (raclette cheese) --- Similarity: 0.555\n",
      "(Smothie) --- (brownie) --- Similarity: 0.428\n",
      "(Saucisse bouillie) --- (roast beef) --- Similarity: 0.300\n",
      "(Sweet & tangy original barbecue sauce) --- (sweet and spicy barbecue sauce) --- Similarity: 0.826\n",
      "(Les grillades du chef brochetyes de poulet chorizo et colombo) --- (sweet and spicy barbecue sauce) --- Similarity: 0.417\n",
      "(Melocotón en Almiba) --- (soymilk) --- Similarity: 0.392\n",
      "(Break oatmeal) --- (oatmeal) --- Similarity: 0.840\n",
      "(Poudre de cacao) --- (raw cacao powder) --- Similarity: 0.641\n",
      "(Penne quattro fromaggi) --- (penne pasta) --- Similarity: 0.417\n",
      "(Moutarde de Dijon) --- (Dijon mustard) --- Similarity: 0.517\n",
      "(Vanille) --- (limoncello) --- Similarity: 0.234\n",
      "(Cocktail d'huiles vierges biologiques Oméga 3&) --- (lemons) --- Similarity: 0.333\n",
      "(Roja Enchilada Sauce) --- (red enchilada sauce) --- Similarity: 0.760\n",
      "(HEB Whole Wheat Ultra Thin & Crispy Pizza Crusts) --- (whole wheat pizza crusts ) --- Similarity: 0.769\n",
      "(pain de mie tranché aux graines de lin et tournesol et à la farine de seig) --- (olive oil) --- Similarity: 0.285\n",
      "(Ciruela pasa) --- (Italian olives) --- Similarity: 0.275\n",
      "(Vloeibare bloemenhoning) --- (wontons) --- Similarity: 0.222\n",
      "(Carotte rapée) --- (limoncello) --- Similarity: 0.365\n",
      "(Bio Café Organic) --- (coffee) --- Similarity: 0.433\n",
      "(Hamburger bovino) --- (hamburger) --- Similarity: 0.771\n",
      "(Merluza Filetes sin piel) --- (whole wheat pizza crusts ) --- Similarity: 0.348\n",
      "(4 vol-au-vent feuilleté) --- (vol - au - vent cases) --- Similarity: 0.624\n",
      "(Iced fancy decorated butter cookies) --- (butter cookies) --- Similarity: 0.794\n",
      "(Purée Pomme & Crème De Marron 100% Plaisir B) --- (italian - flavored croutons) --- Similarity: 0.355\n",
      "(White wine vinegar) --- (white wine vinegar) --- Similarity: 1.000\n",
      "(Sucette en chocolat) --- (pastry flour) --- Similarity: 0.398\n",
      "(Raclette) --- (raclette cheese) --- Similarity: 0.732\n",
      "(Hamburguesa 3) --- (hamburger) --- Similarity: 0.333\n",
      "(Reispapier) --- (tilapia fillet) --- Similarity: 0.368\n",
      "(Haricots blancs) --- (lemons) --- Similarity: 0.420\n",
      "(Classic blend 40 Tea Bags) --- (tea bags) --- Similarity: 0.697\n",
      "(Rodaja de marrajo) --- (limoncello) --- Similarity: 0.257\n",
      "(Corn Flakes) --- (corn flakes) --- Similarity: 1.000\n",
      "(Cocoa puffs cuckoo for chocolatey milk! frosted corn puffs) --- (frozen cream puffs) --- Similarity: 0.624\n",
      "(Sardellenfilets) --- (sardine fillet) --- Similarity: 0.506\n",
      "(Lait demi écré) --- (salami) --- Similarity: 0.220\n",
      "(Pina colada) --- (frozen Pina Colada mix) --- Similarity: 0.783\n",
      "(Croissant salati al sesamo) --- (plain croissants) --- Similarity: 0.660\n",
      "(Rillons de porc) --- (raw cacao powder) --- Similarity: 0.287\n",
      "(Italian Nocellara Olives) --- (Italian olives) --- Similarity: 0.812\n",
      "(Galletas bio) --- (Italian olives) --- Similarity: 0.255\n",
      "(Carolina Gold Sugar Free BBQ Sauce) --- (sweet and spicy barbecue sauce) --- Similarity: 0.569\n",
      "(Espresso cremoso compatibile Dolce Gusto) --- (espresso coffee ) --- Similarity: 0.442\n",
      "(Pilons de poulet jaune) --- (prune) --- Similarity: 0.318\n",
      "(Sandiwch Pollo Light) --- ( coockiw) --- Similarity: 0.297\n",
      "(Kalifornische Mandeln) --- (greek non fat yogurt) --- Similarity: 0.270\n",
      "(Organic mango chunks) --- (frozen mango chunks) --- Similarity: 0.841\n",
      "(Evolution fresh) --- (chestnut puree) --- Similarity: 0.350\n",
      "(Tzatziki) --- (tzatziki) --- Similarity: 1.000\n",
      "(Tomates grappes bio) --- (boneless pork filet) --- Similarity: 0.221\n",
      "(Chocolat Excellence Noir Intense 70%) --- (chocolate bar) --- Similarity: 0.390\n",
      "(Salami suisse) --- (salami) --- Similarity: 0.780\n",
      "(Organic Original Soy Non-Dairy Beverage) --- (soymilk) --- Similarity: 0.632\n",
      "(Gummi worms) --- (gummy worms) --- Similarity: 0.895\n",
      "(Lardons fumé) --- (red enchilada sauce) --- Similarity: 0.342\n",
      "(Meat Ball Stew) --- (meatballs) --- Similarity: 0.737\n",
      "(Sardines) --- (sardines) --- Similarity: 1.000\n",
      "(Whey protein isolate) --- (whey protein) --- Similarity: 0.933\n",
      "(Whey isolado) --- (whey protein) --- Similarity: 0.555\n",
      "(Veggie burgers) --- (veggie burgers) --- Similarity: 1.000\n",
      "(Mirtilli del Piemonte) --- (Italian olives) --- Similarity: 0.382\n",
      "(Filet mignon de porc) --- (espresso coffee ) --- Similarity: 0.249\n"
     ]
    }
   ],
   "source": [
    "from entity_linking import find_most_similar_pairs, read_specified_columns\n",
    "\n",
    "file1_path = \"../csv_file/entity_linking_test.csv\"\n",
    "\n",
    "lists = read_specified_columns(file_path=file1_path, elenco_colonne=[\"off\", \"foodkg\"], delimiter=\",\")\n",
    "\n",
    "list1 = [item[0] for item in lists]\n",
    "list2 = [item[1] for item in lists]\n",
    "\n",
    "most_similar_pairs = find_most_similar_pairs(list1, list2)\n",
    "\n",
    "print(\"Most similar couples:\\n\")\n",
    "for item1, item2, score in most_similar_pairs:\n",
    "    print(f\"({item1}) --- ({item2}) --- Similarity: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNIVERSITY OF BARI METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating embeddings for list2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Titles embeddings: 100%|██████████| 106/106 [00:00<00:00, 192.97batch/s]\n",
      "Calculating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for the most similar recipes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 224.86batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 124.99batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 183.04batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 115.96batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 94.25batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 110.50batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 140.12batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 168.86batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 141.13batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 199.91batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 142.09batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 102.07batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 160.58batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 662.19batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 200.02batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 116.64batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 209.67batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 134.60batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 148.74batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 139.99batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 118.63batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 142.89batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 133.25batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 140.94batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 125.45batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 195.77batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 152.18batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 122.21batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 140.72batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 158.08batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 94.76batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 223.58batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 195.93batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 220.56batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 138.91batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 113.77batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 185.06batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 200.18batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 166.06batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 164.46batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 151.96batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 141.45batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 139.02batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 195.59batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 162.17batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 142.66batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 106.11batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 100.28batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 162.43batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 244.68batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 195.91batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 186.62batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 167.30batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 161.57batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 332.51batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 166.57batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 152.39batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 165.36batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 237.65batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 123.29batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 275.11batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 200.02batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 132.14batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 152.19batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 162.78batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 175.63batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 81.64batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 146.02batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 151.29batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 214.19batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 114.85batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 148.68batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 180.09batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 171.15batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 166.60batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 203.54batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 163.30batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 300.80batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 128.36batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 192.87batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 162.63batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 181.37batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 160.54batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 236.07batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 158.40batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 154.15batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 161.15batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 133.48batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 339.37batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 158.80batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 198.44batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 175.41batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 145.31batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 176.94batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 154.97batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 171.72batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 172.07batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 170.78batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 735.33batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 150.46batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 141.73batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 193.52batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 159.81batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 111.89batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 156.44batch/s]\n",
      "Processing Titles embeddings: 100%|██████████| 1/1 [00:00<00:00, 174.55batch/s]\n",
      "Similarity search: 100%|██████████| 106/106 [00:01<00:00, 104.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar recipe pairs found:\n",
      "\n",
      "(Protein brownie mini) --------- (7 - Up soda) --------- Similarity: 0.886\n",
      "(Tablet) --------- (lollipops) --------- Similarity: 0.819\n",
      "(Saucisse a tartiner 170g) --------- (Dijon mustard) --------- Similarity: 0.881\n",
      "(Noisettes crues) --------- (tzatziki) --------- Similarity: 0.899\n",
      "(Hummus gegrilde groenten) --------- (Dijon mustard) --------- Similarity: 0.894\n",
      "(Land O' Frost Premium Cured Roast Beef) --------- (chicken sandwich steaks) --------- Similarity: 0.855\n",
      "(pepper jelly) --------- (pepper jelly) --------- Similarity: 1.000\n",
      "(Whole Chocolate Milk) --------- (chocolate bar) --------- Similarity: 0.888\n",
      "(Filet de poulet) --------- (Dijon mustard) --------- Similarity: 0.894\n",
      "(Olivenmix mit Kräuter) --------- (prosciutto ham) --------- Similarity: 0.844\n",
      "(Rinder-Hackfleisch) --------- (tzatziki) --------- Similarity: 0.846\n",
      "(ICA i♥eco 12 ekologiska ägg från frigående) --------- (tzatziki) --------- Similarity: 0.850\n",
      "(Harina de trigo especial reposteria) --------- (tzatziki) --------- Similarity: 0.880\n",
      "(Sardines in water) --------- (slivered smoked salmon) --------- Similarity: 0.891\n",
      "(Oeufs frais) --------- (Dijon mustard) --------- Similarity: 0.885\n",
      "(Gelée de piments d’espele) --------- (Dijon mustard) --------- Similarity: 0.890\n",
      "(Brente Mandler) --------- (tzatziki) --------- Similarity: 0.893\n",
      "(Cereal) --------- (sardine fillet) --------- Similarity: 0.892\n",
      "(5 fűszeres paradicsomszó) --------- (tzatziki) --------- Similarity: 0.853\n",
      "(Jambon traditionnel) --------- (tzatziki) --------- Similarity: 0.875\n",
      "(Hershey’s cookies ´n’ ) --------- (cookies) --------- Similarity: 0.883\n",
      "(Salsiccia luganega) --------- (tilapia fillet) --------- Similarity: 0.870\n",
      "(Ceviche tilapia) --------- (tilapia fillet) --------- Similarity: 0.920\n",
      "(Olive oil) --------- (olive oil) --------- Similarity: 0.954\n",
      "(Fraises) --------- (Italian olives) --------- Similarity: 0.900\n",
      "(Rillette de Bar Poivre rouge de Kampot) --------- (Dijon mustard) --------- Similarity: 0.877\n",
      "(Export Sodas) --------- (basmati rice) --------- Similarity: 0.888\n",
      "(Vitalis light croccante chioccolato) --------- (virgin olive oil) --------- Similarity: 0.860\n",
      "(Pizza forno de pedra 4 estaçõ) --------- (prosciutto ham) --------- Similarity: 0.872\n",
      "(Nougat Limoncello) --------- (Dijon mustard) --------- Similarity: 0.895\n",
      "(Glace noisette) --------- (tzatziki) --------- Similarity: 0.906\n",
      "(Suppennudeln OFFEN) --------- (tzatziki) --------- Similarity: 0.880\n",
      "(Organic lemons) --------- (veggie burgers) --------- Similarity: 0.940\n",
      "(Speck alto adige Igp) --------- (Dijon mustard) --------- Similarity: 0.863\n",
      "(Melange d olives) --------- (Dijon mustard) --------- Similarity: 0.908\n",
      "(Bens original riz basmati) --------- (limoncello) --------- Similarity: 0.889\n",
      "(Emprésuré chocolat inten) --------- (tzatziki) --------- Similarity: 0.865\n",
      "(Provolone dolce) --------- (prosciutto ham) --------- Similarity: 0.908\n",
      "(Gluten free italian crostini) --------- (almonds) --------- Similarity: 0.877\n",
      "(Fave Intere Salate) --------- (prosciutto ham) --------- Similarity: 0.871\n",
      "(Slightly Salted Butter) --------- (oatmeal) --------- Similarity: 0.852\n",
      "(Iogurte de Açaí com Banana - Frutap - Frut) --------- (tzatziki) --------- Similarity: 0.873\n",
      "(Labeyrie tranches de saumon fum�) --------- (Dijon mustard) --------- Similarity: 0.860\n",
      "(Sensational Burger) --------- (7 - Up soda) --------- Similarity: 0.893\n",
      "(Habanero Lime Cream Cheese Wontons) --------- (low - carb barbecue sauce) --------- Similarity: 0.877\n",
      "(Smothie) --------- ( coockiw) --------- Similarity: 0.887\n",
      "(Saucisse bouillie) --------- (Dijon mustard) --------- Similarity: 0.892\n",
      "(Sweet & tangy original barbecue sauce) --------- (slivered smoked salmon) --------- Similarity: 0.894\n",
      "(Les grillades du chef brochetyes de poulet chorizo et colombo) --------- (tzatziki) --------- Similarity: 0.858\n",
      "(Melocotón en Almiba) --------- (tzatziki) --------- Similarity: 0.857\n",
      "(Break oatmeal) --------- (oatmeal) --------- Similarity: 0.816\n",
      "(Poudre de cacao) --------- (basmati rice) --------- Similarity: 0.877\n",
      "(Penne quattro fromaggi) --------- (prosciutto ham) --------- Similarity: 0.896\n",
      "(Moutarde de Dijon) --------- (Dijon mustard) --------- Similarity: 0.881\n",
      "(Vanille) --------- (limoncello) --------- Similarity: 0.880\n",
      "(Cocktail d'huiles vierges biologiques Oméga 3&) --------- (tzatziki) --------- Similarity: 0.887\n",
      "(Roja Enchilada Sauce) --------- (limoncello) --------- Similarity: 0.848\n",
      "(HEB Whole Wheat Ultra Thin & Crispy Pizza Crusts) --------- (veggie burgers) --------- Similarity: 0.894\n",
      "(pain de mie tranché aux graines de lin et tournesol et à la farine de seig) --------- (tzatziki) --------- Similarity: 0.839\n",
      "(Ciruela pasa) --------- (prosciutto ham) --------- Similarity: 0.864\n",
      "(Vloeibare bloemenhoning) --------- (Dijon mustard) --------- Similarity: 0.885\n",
      "(Carotte rapée) --------- (Dijon mustard) --------- Similarity: 0.889\n",
      "(Bio Café Organic) --------- (basmati rice) --------- Similarity: 0.901\n",
      "(Hamburger bovino) --------- (Dijon mustard) --------- Similarity: 0.893\n",
      "(Merluza Filetes sin piel) --------- (prosciutto ham) --------- Similarity: 0.840\n",
      "(4 vol-au-vent feuilleté) --------- (vol - au - vent cases) --------- Similarity: 0.913\n",
      "(Iced fancy decorated butter cookies) --------- (frozen pizza) --------- Similarity: 0.852\n",
      "(Purée Pomme & Crème De Marron 100% Plaisir B) --------- (Dijon mustard) --------- Similarity: 0.848\n",
      "(White wine vinegar) --------- (white wine vinegar) --------- Similarity: 0.976\n",
      "(Sucette en chocolat) --------- (limoncello) --------- Similarity: 0.889\n",
      "(Raclette) --------- (tzatziki) --------- Similarity: 0.858\n",
      "(Hamburguesa 3) --------- (frozen Pina Colada mix) --------- Similarity: 0.858\n",
      "(Reispapier) --------- (soymilk) --------- Similarity: 0.862\n",
      "(Haricots blancs) --------- (Dijon mustard) --------- Similarity: 0.904\n",
      "(Classic blend 40 Tea Bags) --------- (frozen Pina Colada mix) --------- Similarity: 0.868\n",
      "(Rodaja de marrajo) --------- (Dijon mustard) --------- Similarity: 0.873\n",
      "(Corn Flakes) --------- (lollipops) --------- Similarity: 0.894\n",
      "(Cocoa puffs cuckoo for chocolatey milk! frosted corn puffs) --------- (chocolate bar) --------- Similarity: 0.860\n",
      "(Sardellenfilets) --------- (tzatziki) --------- Similarity: 0.871\n",
      "(Lait demi écré) --------- (tzatziki) --------- Similarity: 0.881\n",
      "(Pina colada) --------- (tilapia fillet) --------- Similarity: 0.890\n",
      "(Croissant salati al sesamo) --------- (prosciutto ham) --------- Similarity: 0.900\n",
      "(Rillons de porc) --------- (Dijon mustard) --------- Similarity: 0.898\n",
      "(Italian Nocellara Olives) --------- (Italian olives) --------- Similarity: 0.901\n",
      "(Galletas bio) --------- (tzatziki) --------- Similarity: 0.890\n",
      "(Carolina Gold Sugar Free BBQ Sauce) --------- (frozen Pina Colada mix) --------- Similarity: 0.844\n",
      "(Espresso cremoso compatibile Dolce Gusto) --------- (limoncello) --------- Similarity: 0.884\n",
      "(Pilons de poulet jaune) --------- (Dijon mustard) --------- Similarity: 0.908\n",
      "(Sandiwch Pollo Light) --------- ( coockiw) --------- Similarity: 0.886\n",
      "(Kalifornische Mandeln) --------- (tzatziki) --------- Similarity: 0.884\n",
      "(Organic mango chunks) --------- (frozen mango chunks) --------- Similarity: 0.918\n",
      "(Evolution fresh) --------- (tzatziki) --------- Similarity: 0.876\n",
      "(Tzatziki) --------- (tzatziki) --------- Similarity: 0.964\n",
      "(Tomates grappes bio) --------- (vol - au - vent cases) --------- Similarity: 0.883\n",
      "(Chocolat Excellence Noir Intense 70%) --------- (slivered smoked salmon) --------- Similarity: 0.859\n",
      "(Salami suisse) --------- (tzatziki) --------- Similarity: 0.871\n",
      "(Organic Original Soy Non-Dairy Beverage) --------- (slivered smoked salmon) --------- Similarity: 0.864\n",
      "(Gummi worms) --------- (gummy worms) --------- Similarity: 0.926\n",
      "(Lardons fumé) --------- (tzatziki) --------- Similarity: 0.890\n",
      "(Meat Ball Stew) --------- (slivered smoked salmon) --------- Similarity: 0.862\n",
      "(Sardines) --------- (sardines) --------- Similarity: 0.913\n",
      "(Whey protein isolate) --------- (whey protein) --------- Similarity: 0.883\n",
      "(Whey isolado) --------- (tzatziki) --------- Similarity: 0.884\n",
      "(Veggie burgers) --------- (veggie burgers) --------- Similarity: 0.960\n",
      "(Mirtilli del Piemonte) --------- (prosciutto ham) --------- Similarity: 0.865\n",
      "(Filet mignon de porc) --------- (Dijon mustard) --------- Similarity: 0.894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from entity_linking import (\n",
    "    RecipeTransformer,\n",
    "    compute_embeddings,\n",
    "    find_similar_by_title,\n",
    "    read_specified_columns,\n",
    ")\n",
    "\n",
    "file1_path = \"../csv_file/entity_linking_test.csv\"\n",
    "\n",
    "lists = read_specified_columns(file_path=file1_path, elenco_colonne=[\"off\", \"foodkg\"], delimiter=\",\")\n",
    "\n",
    "list1 = [item[0] for item in lists]\n",
    "list2 = [item[1] for item in lists]\n",
    "\n",
    "\n",
    "# Initialize the transformer\n",
    "transformer_name = \"davanstrien/autotrain-recipes-2451975973\"\n",
    "transformer = RecipeTransformer(transformer_name)\n",
    "\n",
    "# Compute embeddings for all recipes in list2\n",
    "print(\"Calculating embeddings for list2...\")\n",
    "embeddings2 = compute_embeddings(list2, transformer)\n",
    "\n",
    "# Create a list of tuples (index, title) for list2\n",
    "entities_list2 = list(enumerate(iterable=list2))\n",
    "\n",
    "# Find the most similar recipe for each item in list1\n",
    "most_similar_pairs = []\n",
    "print(\"Searching for the most similar recipes...\")\n",
    "for recipe_title in tqdm(list1, desc=\"Similarity search\"):\n",
    "    similar_recipe, similarity_score = find_similar_by_title(\n",
    "        recipe_title, entities_list2, embeddings2, transformer\n",
    "    )\n",
    "    most_similar_pairs.append((recipe_title, similar_recipe[1], similarity_score))\n",
    "\n",
    "# Output the results\n",
    "print(\"Most similar recipe pairs found:\\n\")\n",
    "for item1, item2, score in most_similar_pairs:\n",
    "    print(f\"({item1}) --------- ({item2}) --------- Similarity: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IBRID METHOD WITH INDICATOR TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual contribution [(0.4346590819370404, 'Pasta', 'Pizza'), (0.3310670316900095, 'Pane', 'Pizza')]\n",
      "negative contribution [(0.35608773076070105, 'Pasta', 'Pizza'), (0.30325937271118164, 'Pane', 'Pizza')]\n",
      "positive contribution [(0.4426902711391449, 'Pasta', 'Pizza'), (0.30325937271118164, 'Pane', 'Pizza')]\n",
      "no contribution [(0.3926902711391449, 'pasta', 'pizza'), (0.30325937271118164, 'pane', 'pizza')]\n"
     ]
    }
   ],
   "source": [
    "from entity_linking import find_k_most_similar_pairs_with_indicators\n",
    "\n",
    "list1 = [(\"Pasta\", 30, 5, 10, \"Pasta\"), (\"Pane\", 50, 1, 10, \"Pane\")]\n",
    "list2 = [(\"Riso\", 40, 2, 8, \"Riso\"), (\"Pizza\", 20, 10, 12, \"Pizza\")]\n",
    "result = find_k_most_similar_pairs_with_indicators(list1, list2, use_indicator=True)\n",
    "print(\"actual contribution\", result)\n",
    "\n",
    "list1 = [(\"Pasta\", 100, 0, 0, \"Pasta\"), (\"Pane\", 0, 0, 0, \"Pane\")]\n",
    "list2 = [(\"Riso\", 0, 2, 8, \"Riso\"), (\"Pizza\", 0, 50, 50, \"Pizza\")]\n",
    "result = find_k_most_similar_pairs_with_indicators(list1, list2, use_indicator=True)\n",
    "print(\"negative contribution\", result)\n",
    "\n",
    "list1 = [(\"Pasta\", 33, 33, 33, \"Pasta\"), (\"Pane\", 0, 0, 0, \"Pane\")]\n",
    "list2 = [(\"Riso\", 0, 2, 8, \"Riso\"), (\"Pizza\", 33, 33, 33 , \"Pizza\")]\n",
    "result = find_k_most_similar_pairs_with_indicators(list1, list2, use_indicator=True)\n",
    "print(\"positive contribution\", result)\n",
    "\n",
    "list1 = [(\"pasta\", \"pasta\"), (\"pane\", \"pane\")]\n",
    "list2 = [(\"riso\", \"riso\"), (\"pizza\", \"pizza\")]\n",
    "result = find_k_most_similar_pairs_with_indicators(list1, list2)\n",
    "print(\"no contribution\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST OF VARIOUS BERT MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d67b140901d747a08999b3f4954e62cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 224.00 MiB. GPU 0 has a total capacity of 44.55 GiB of which 174.06 MiB is free. Process 1245088 has 16.12 GiB memory in use. Process 1248677 has 14.97 GiB memory in use. Process 1366155 has 12.15 GiB memory in use. Including non-PyTorch memory, this process has 1.12 GiB memory in use. Of the allocated memory 884.00 MiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 56\u001b[0m\n\u001b[1;32m     53\u001b[0m writer\u001b[38;5;241m.\u001b[39mwriterow(column_names)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m list_of_models:\n\u001b[0;32m---> 56\u001b[0m     model_name, vocab_size, number_of_parameters, accuracy, accuracy_considered, number_of_considered_element, threshold \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_entity_linking_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreshold\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m modelz, vocab_sizez, number_of_parametersz, accuracyz, accuracy_consideredz, number_of_considered_elementz, thresholdz,  \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(model_name, vocab_size, number_of_parameters, accuracy, accuracy_considered, number_of_considered_element, threshold):\n\u001b[1;32m     60\u001b[0m         writer\u001b[38;5;241m.\u001b[39mwriterow([model, vocab_sizez, number_of_parametersz, \u001b[38;5;28mround\u001b[39m(accuracyz, \u001b[38;5;241m2\u001b[39m), \u001b[38;5;28mround\u001b[39m(accuracy_consideredz) , number_of_considered_elementz, thresholdz])\n",
      "File \u001b[0;32m~/kgeats/entity_linking_file/entity_linking.py:362\u001b[0m, in \u001b[0;36mevaluate_entity_linking_method\u001b[0;34m(data, model, show_progress, threshold_list)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;66;03m# Apply the method\u001b[39;00m\n\u001b[1;32m    361\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# Number of results to consider\u001b[39;00m\n\u001b[0;32m--> 362\u001b[0m linked_entities \u001b[38;5;241m=\u001b[39m \u001b[43mfind_k_most_similar_pairs_with_indicators\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlist1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlist2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;66;03m# Evaluate results\u001b[39;00m\n\u001b[1;32m    367\u001b[0m accuracy_list \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/kgeats/entity_linking_file/entity_linking.py:276\u001b[0m, in \u001b[0;36mfind_k_most_similar_pairs_with_indicators\u001b[0;34m(list1, list2, k, model, use_indicator, batch_size)\u001b[0m\n\u001b[1;32m    273\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;66;03m# Load the model\u001b[39;00m\n\u001b[0;32m--> 276\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSentenceTransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_indicator:\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;66;03m# Ensure each element in list1 and list2 has 4 elements by appending (0, 0, 0)\u001b[39;00m\n\u001b[1;32m    280\u001b[0m     list1 \u001b[38;5;241m=\u001b[39m [(item[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, item[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m list1]\n",
      "File \u001b[0;32m~/miniconda3/envs/ambientez/lib/python3.13/site-packages/sentence_transformers/SentenceTransformer.py:347\u001b[0m, in \u001b[0;36mSentenceTransformer.__init__\u001b[0;34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, similarity_fn_name, cache_folder, trust_remote_code, revision, local_files_only, token, use_auth_token, truncate_dim, model_kwargs, tokenizer_kwargs, config_kwargs, model_card_data, backend)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_hpu_graph_enabled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_prompt_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_prompt_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompts:\n",
      "File \u001b[0;32m~/miniconda3/envs/ambientez/lib/python3.13/site-packages/torch/nn/modules/module.py:1340\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1337\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1338\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ambientez/lib/python3.13/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ambientez/lib/python3.13/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 900 (3 times)]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/ambientez/lib/python3.13/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ambientez/lib/python3.13/site-packages/torch/nn/modules/module.py:927\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 927\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    930\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ambientez/lib/python3.13/site-packages/torch/nn/modules/module.py:1326\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1320\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1321\u001b[0m             device,\n\u001b[1;32m   1322\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1323\u001b[0m             non_blocking,\n\u001b[1;32m   1324\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1325\u001b[0m         )\n\u001b[0;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 224.00 MiB. GPU 0 has a total capacity of 44.55 GiB of which 174.06 MiB is free. Process 1245088 has 16.12 GiB memory in use. Process 1248677 has 14.97 GiB memory in use. Process 1366155 has 12.15 GiB memory in use. Including non-PyTorch memory, this process has 1.12 GiB memory in use. Of the allocated memory 884.00 MiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "from entity_linking import read_specified_columns, evaluate_entity_linking_method\n",
    "import csv\n",
    "\n",
    "#huggingface-cli login\n",
    "#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\n",
    "\n",
    "file_path = \"../csv_file/entity_linking_test_normalized.csv\"\n",
    "column_list = [\"off_normalized\", \"foodkg_normalized\"]\n",
    "data = read_specified_columns(file_path, elenco_colonne=column_list, delimiter=\",\")\n",
    "\n",
    "#https://huggingface.co/spaces/mteb/leaderboard 09/12/2024\n",
    "list_of_models = [\n",
    "    \n",
    "    #top 5 in pair classification (around 10000000 parameter)\n",
    "    #voyage è a pagamento\n",
    "    #\"meta-llama/Meta-Llama-3-8B-Instruct\", # have problem with padding\n",
    "    \"nvidia/NV-Embed-v2\",\n",
    "    \"Salesforce/SFR-Embedding-Mistral\",\n",
    "    \"compressa-ai/Compressa-Embeddings\",\n",
    "\n",
    "    # top 3 under 1000000 parameters\n",
    "    \"dunzhang/stella_en_400M_v5\",\n",
    "    \"llmrails/ember-v1\",\n",
    "    \"WhereIsAI/UAE-Large-V1\",\n",
    "\n",
    "    # top 3 under 100000 parameters\n",
    "    \"infgrad/stella-base-en-v2\",\n",
    "    \"intfloat/e5-small\",\n",
    "    \"BAAI/bge-small-en-v1.5\", \n",
    "\n",
    "    #top 5 overall\n",
    "    #nvidia/NV-Embed-v2 alredy tested\n",
    "    \"dunzhang/stella_en_1.5B_v5\",\n",
    "    \"BAAI/bge-en-icl\",\n",
    "    \"blevlabs/stella_en_v5\",\n",
    "    \"Salesforce/SFR-Embedding-2_R\",\n",
    "\n",
    "    # top 3 in sts\n",
    "    \"Lajavaness/bilingual-embedding-large\",\n",
    "    \"ilhamdprastyo/jina-embeddings-v3-tei\",\n",
    "    \"jinaai/jina-embeddings-v3\"\n",
    "    ]\n",
    "\n",
    "\n",
    "column_names = [\"model_name\", \"vocab_size\", \"number_of_parameters\", \"accuracy\", \"accuracy_on_considered\", \"number_of_considered_element\", \"threshold\", ]\n",
    "threshold = [(i/100) for i in  range(80, 100, 1)]\n",
    "\n",
    "output_file = \"../csv_file/bert_comparison.csv\"\n",
    "\n",
    "with open(output_file, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(column_names)\n",
    "    \n",
    "    for model in list_of_models:\n",
    "        model_name, vocab_size, number_of_parameters, accuracy, accuracy_considered, number_of_considered_element, threshold = evaluate_entity_linking_method(\n",
    "            data, show_progress=True, model=model, threshold_list=threshold\n",
    "        )\n",
    "        for modelz, vocab_sizez, number_of_parametersz, accuracyz, accuracy_consideredz, number_of_considered_elementz, thresholdz,  in zip(model_name, vocab_size, number_of_parameters, accuracy, accuracy_considered, number_of_considered_element, threshold):\n",
    "            writer.writerow([model, vocab_sizez, number_of_parametersz, round(accuracyz, 2), round(accuracy_consideredz) , number_of_considered_elementz, thresholdz])\n",
    "\n",
    "print(f\"file created {output_file}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ambientez",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
